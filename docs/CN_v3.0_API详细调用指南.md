n# ğŸ“˜ RimAI Framework v3.0 APIè¯¦ç»†è°ƒç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›RimAI Framework v3.0æ‰€æœ‰APIçš„è¯¦ç»†è°ƒç”¨æ–¹æ³•ã€å‚æ•°è¯´æ˜å’Œé«˜çº§ç”¨æ³•ã€‚é€‚åˆéœ€è¦æ·±å…¥äº†è§£æ¡†æ¶åŠŸèƒ½çš„å¼€å‘è€…ã€‚

## ğŸ¯ æ ¸å¿ƒAPIç±»ï¼šRimAIAPI

`RimAIAPI` æ˜¯æ¡†æ¶çš„ç»Ÿä¸€å…¥å£ç‚¹ï¼Œæä¾›æ‰€æœ‰ä¸»è¦åŠŸèƒ½çš„é™æ€æ–¹æ³•ã€‚

### å‘½åç©ºé—´
```csharp
using RimAI.Framework.API;
using RimAI.Framework.LLM.Models;
```

## ğŸ“ æ¶ˆæ¯å‘é€API

### 1. SendMessageAsync - æ ‡å‡†æ¶ˆæ¯å‘é€

#### æ–¹æ³•ç­¾å
```csharp
public static async Task<LLMResponse> SendMessageAsync(
    string message, 
    LLMRequestOptions options = null
)
```

#### å‚æ•°è¯¦è§£

**message (string, å¿…éœ€)**
- å‘é€ç»™LLMçš„æ¶ˆæ¯å†…å®¹
- æ”¯æŒå¤šè¡Œæ–‡æœ¬å’Œç‰¹æ®Šå­—ç¬¦
- å»ºè®®é•¿åº¦ï¼š1-8000å­—ç¬¦

**options (LLMRequestOptions, å¯é€‰)**
- è¯·æ±‚é…ç½®é€‰é¡¹ï¼Œnullæ—¶ä½¿ç”¨é»˜è®¤é…ç½®
- è¯¦ç»†å‚æ•°è§ [LLMRequestOptions](#llmrequestoptions-è¯¦ç»†å‚æ•°)

#### è¿”å›å€¼ï¼šLLMResponse
```csharp
public class LLMResponse
{
    public string Content { get; set; }           // å“åº”å†…å®¹
    public bool IsSuccess { get; set; }           // æ˜¯å¦æˆåŠŸ
    public string ErrorMessage { get; set; }     // é”™è¯¯æ¶ˆæ¯(å¦‚æœæœ‰)
    public TimeSpan ResponseTime { get; set; }   // å“åº”æ—¶é—´
    public int TokensUsed { get; set; }          // ä½¿ç”¨çš„Tokenæ•°é‡
    public bool FromCache { get; set; }          // æ˜¯å¦æ¥è‡ªç¼“å­˜
    public string RequestId { get; set; }        // è¯·æ±‚å”¯ä¸€æ ‡è¯†
}
```

#### ä½¿ç”¨ç¤ºä¾‹

**åŸºç¡€è°ƒç”¨**
```csharp
// æœ€ç®€å•çš„è°ƒç”¨æ–¹å¼
var response = await RimAIAPI.SendMessageAsync("Hello, AI!");
if (response.IsSuccess)
{
    Log.Message($"AIå›å¤: {response.Content}");
    Log.Message($"å“åº”æ—¶é—´: {response.ResponseTime.TotalMilliseconds}ms");
    Log.Message($"æ¥è‡ªç¼“å­˜: {response.FromCache}");
}
```

**å¸¦å‚æ•°è°ƒç”¨**
```csharp
// ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
var options = new LLMRequestOptions
{
    Temperature = 0.8f,
    MaxTokens = 500,
    EnableCaching = true
};

var response = await RimAIAPI.SendMessageAsync(
    "å†™ä¸€ä¸ªå…³äºRimWorldçš„çŸ­æ•…äº‹", 
    options
);
```

**é”™è¯¯å¤„ç†**
```csharp
try
{
    var response = await RimAIAPI.SendMessageAsync("ä½ å¥½");
    if (!response.IsSuccess)
    {
        Log.Error($"è¯·æ±‚å¤±è´¥: {response.ErrorMessage}");
        return;
    }
    
    // å¤„ç†æˆåŠŸå“åº”
    ProcessResponse(response.Content);
}
catch (RimAIException ex)
{
    Log.Error($"RimAIå¼‚å¸¸: {ex.Message}");
}
catch (Exception ex)
{
    Log.Error($"æœªçŸ¥é”™è¯¯: {ex.Message}");
}
```

### 2. SendMessageStreamAsync - æµå¼æ¶ˆæ¯å‘é€

#### æ–¹æ³•ç­¾å
```csharp
public static async Task SendMessageStreamAsync(
    string message,
    Action<string> onChunkReceived,
    LLMRequestOptions options = null,
    CancellationToken cancellationToken = default
)
```

#### å‚æ•°è¯¦è§£

**message (string, å¿…éœ€)**
- å‘é€ç»™LLMçš„æ¶ˆæ¯å†…å®¹

**onChunkReceived (Action<string>, å¿…éœ€)**
- æ¥æ”¶å“åº”å—çš„å›è°ƒå‡½æ•°
- æ¯æ¬¡æ”¶åˆ°æ–°çš„å“åº”ç‰‡æ®µæ—¶è§¦å‘
- å‚æ•°æ˜¯å“åº”å†…å®¹çš„ç‰‡æ®µ

**options (LLMRequestOptions, å¯é€‰)**
- è¯·æ±‚é…ç½®é€‰é¡¹

**cancellationToken (CancellationToken, å¯é€‰)**
- ç”¨äºå–æ¶ˆé•¿æ—¶é—´è¿è¡Œçš„è¯·æ±‚

#### ä½¿ç”¨ç¤ºä¾‹

**åŸºç¡€æµå¼è°ƒç”¨**
```csharp
var fullResponse = new StringBuilder();

await RimAIAPI.SendMessageStreamAsync(
    "è¯¦ç»†è§£é‡ŠRimWorldçš„æˆ˜æ–—ç³»ç»Ÿ",
    chunk => {
        // å®æ—¶æ¥æ”¶å“åº”ç‰‡æ®µ
        Log.Message($"æ”¶åˆ°: {chunk}");
        fullResponse.Append(chunk);
    }
);

Log.Message($"å®Œæ•´å“åº”: {fullResponse.ToString()}");
```

**å¸¦å–æ¶ˆåŠŸèƒ½çš„æµå¼è°ƒç”¨**
```csharp
var cts = new CancellationTokenSource();
var responseBuilder = new StringBuilder();

// è®¾ç½®5ç§’è¶…æ—¶
cts.CancelAfter(TimeSpan.FromSeconds(5));

try
{
    await RimAIAPI.SendMessageStreamAsync(
        "å†™ä¸€ç¯‡é•¿ç¯‡å°è¯´",
        chunk => {
            responseBuilder.Append(chunk);
            
            // å¯ä»¥åœ¨å›è°ƒä¸­æ£€æŸ¥æ¡ä»¶å¹¶å–æ¶ˆ
            if (responseBuilder.Length > 1000)
            {
                cts.Cancel();
            }
        },
        options: new LLMRequestOptions { Temperature = 0.9f },
        cancellationToken: cts.Token
    );
}
catch (OperationCanceledException)
{
    Log.Message("è¯·æ±‚è¢«å–æ¶ˆ");
}
```

**å®æ—¶UIæ›´æ–°ç¤ºä¾‹**
```csharp
var dialog = Find.WindowStack.WindowOfType<MyAIDialog>();

await RimAIAPI.SendMessageStreamAsync(
    userInput,
    chunk => {
        // åœ¨ä¸»çº¿ç¨‹æ›´æ–°UI
        if (Current.ProgramState == ProgramState.Playing)
        {
            dialog?.UpdateResponseText(chunk);
        }
    },
    new LLMRequestOptions { EnableCaching = false }
);
```

### 3. SendBatchRequestAsync - æ‰¹é‡è¯·æ±‚å¤„ç†

#### æ–¹æ³•ç­¾å
```csharp
public static async Task<List<LLMResponse>> SendBatchRequestAsync(
    List<string> messages,
    LLMRequestOptions options = null
)
```

#### å‚æ•°è¯¦è§£

**messages (List<string>, å¿…éœ€)**
- è¦æ‰¹é‡å¤„ç†çš„æ¶ˆæ¯åˆ—è¡¨
- å»ºè®®æ‰¹é‡å¤§å°ï¼š1-10ä¸ªæ¶ˆæ¯
- æ¡†æ¶ä¼šè‡ªåŠ¨ä¼˜åŒ–å¹¶å‘å¤„ç†

**options (LLMRequestOptions, å¯é€‰)**
- åº”ç”¨äºæ‰€æœ‰è¯·æ±‚çš„é…ç½®é€‰é¡¹

#### è¿”å›å€¼ï¼šList<LLMResponse>
- è¿”å›å“åº”åˆ—è¡¨ï¼Œé¡ºåºä¸è¾“å…¥æ¶ˆæ¯å¯¹åº”
- å³ä½¿æŸä¸ªè¯·æ±‚å¤±è´¥ï¼Œå…¶ä»–è¯·æ±‚ä»ä¼šç»§ç»­å¤„ç†

#### ä½¿ç”¨ç¤ºä¾‹

**æ‰¹é‡ç¿»è¯‘**
```csharp
var texts = new List<string>
{
    "Hello World",
    "Good Morning", 
    "How are you?",
    "Thank you"
};

var responses = await RimAIAPI.SendBatchRequestAsync(
    texts.Select(t => $"å°†ä»¥ä¸‹è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡ï¼š{t}").ToList(),
    new LLMRequestOptions { Temperature = 0.3f }
);

for (int i = 0; i < responses.Count; i++)
{
    if (responses[i].IsSuccess)
    {
        Log.Message($"{texts[i]} -> {responses[i].Content}");
    }
    else
    {
        Log.Error($"ç¿»è¯‘å¤±è´¥: {texts[i]} - {responses[i].ErrorMessage}");
    }
}
```

**æ‰¹é‡æ•°æ®åˆ†æ**
```csharp
var dataQueries = new List<string>
{
    "åˆ†æå½“å‰æ®–æ°‘åœ°çš„é£Ÿç‰©çŠ¶å†µ",
    "è¯„ä¼°æ®–æ°‘åœ°çš„é˜²å¾¡èƒ½åŠ›", 
    "æ£€æŸ¥æ®–æ°‘åœ°çš„å¿ƒæƒ…çŠ¶æ€",
    "ç»Ÿè®¡æ®–æ°‘åœ°çš„èµ„æºæƒ…å†µ"
};

var options = new LLMRequestOptions
{
    MaxTokens = 300,
    Temperature = 0.5f,
    EnableCaching = true
};

var reports = await RimAIAPI.SendBatchRequestAsync(dataQueries, options);

// å¹¶è¡Œå¤„ç†ç»“æœ
Parallel.ForEach(reports.Where(r => r.IsSuccess), response => {
    ProcessAnalysisReport(response.Content);
});
```

## âš™ï¸ LLMRequestOptions è¯¦ç»†å‚æ•°

### åŸºç¡€å‚æ•°

```csharp
public class LLMRequestOptions
{
    // æ¸©åº¦æ§åˆ¶ (0.0-2.0)
    public float? Temperature { get; set; }
    
    // æœ€å¤§è¿”å›Tokenæ•°
    public int? MaxTokens { get; set; }
    
    // æ˜¯å¦å¯ç”¨ç¼“å­˜
    public bool EnableCaching { get; set; } = true;
    
    // è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)
    public int? TimeoutSeconds { get; set; }
    
    // é‡è¯•æ¬¡æ•°
    public int? RetryCount { get; set; }
    
    // Top-pé‡‡æ ·å‚æ•°
    public float? TopP { get; set; }
    
    // é¢‘ç‡æƒ©ç½š
    public float? FrequencyPenalty { get; set; }
    
    // å­˜åœ¨æƒ©ç½š
    public float? PresencePenalty { get; set; }
    
    // åœæ­¢è¯åˆ—è¡¨
    public List<string> StopWords { get; set; }
    
    // è‡ªå®šä¹‰HTTPå¤´
    public Dictionary<string, string> CustomHeaders { get; set; }
    
    // ç”¨æˆ·æ ‡è¯†
    public string UserId { get; set; }
}
```

### å‚æ•°è¯¦è§£

**Temperature (float?, 0.0-2.0)**
- æ§åˆ¶å“åº”çš„éšæœºæ€§å’Œåˆ›é€ æ€§
- 0.0: ç¡®å®šæ€§è¾“å‡ºï¼Œé€‚åˆäº‹å®æ€§é—®é¢˜
- 0.7: å¹³è¡¡åˆ›é€ æ€§å’Œå‡†ç¡®æ€§ï¼Œé€‚åˆä¸€èˆ¬å¯¹è¯
- 1.0: æ›´æœ‰åˆ›é€ æ€§ï¼Œé€‚åˆåˆ›æ„å†™ä½œ
- 2.0: é«˜åº¦éšæœºï¼Œé€‚åˆå¤´è„‘é£æš´

```csharp
// äº‹å®æ€§é—®é¢˜ - ä½æ¸©åº¦
var factualOptions = new LLMRequestOptions { Temperature = 0.1f };
var response = await RimAIAPI.SendMessageAsync("RimWorldçš„å‘å¸ƒæ—¶é—´æ˜¯ï¼Ÿ", factualOptions);

// åˆ›æ„å†™ä½œ - é«˜æ¸©åº¦
var creativeOptions = new LLMRequestOptions { Temperature = 1.2f };
var story = await RimAIAPI.SendMessageAsync("å†™ä¸€ä¸ªç§‘å¹»çŸ­æ•…äº‹", creativeOptions);
```

**MaxTokens (int?)**
- é™åˆ¶è¿”å›å†…å®¹çš„é•¿åº¦
- 1 token â‰ˆ 0.75ä¸ªè‹±æ–‡å•è¯ â‰ˆ 0.5ä¸ªä¸­æ–‡å­—ç¬¦
- å»ºè®®å€¼ï¼š50-2000

```csharp
// ç®€çŸ­å›ç­”
var shortOptions = new LLMRequestOptions { MaxTokens = 50 };

// è¯¦ç»†å›ç­”
var detailedOptions = new LLMRequestOptions { MaxTokens = 1000 };
```

**EnableCaching (bool)**
- æ˜¯å¦å¯ç”¨å“åº”ç¼“å­˜
- true: ç›¸åŒè¯·æ±‚ä½¿ç”¨ç¼“å­˜ï¼Œæé«˜æ€§èƒ½
- false: æ¯æ¬¡éƒ½å‘é€æ–°è¯·æ±‚

#### ğŸ” æ·±åº¦è§£æï¼šç¼“å­˜ç›¸ä¼¼æ€§åˆ¤æ–­æœºåˆ¶

**ç¼“å­˜é”®ç”Ÿæˆç®—æ³•**ï¼š
```
ç¼“å­˜é”® = LLM:{æ¶ˆæ¯å“ˆå¸Œ}:temp={Temperature}:maxtok={MaxTokens}:model={Model}:json={JsonMode}:schema={SchemaHash}:topp={TopP}:...
```

**å½±å“ç¼“å­˜å‘½ä¸­çš„å‚æ•°**ï¼š
- **æ¶ˆæ¯å†…å®¹**ï¼šä½¿ç”¨ `GetHashCode()` è®¡ç®—æ–‡æœ¬å“ˆå¸Œ
- **Temperature**ï¼šåˆ›é€ æ€§å‚æ•°ï¼Œå¿…é¡»å®Œå…¨åŒ¹é…
- **MaxTokens**ï¼šæœ€å¤§ä»¤ç‰Œæ•°ï¼Œå¿…é¡»ä¸€è‡´
- **Model**ï¼šAIæ¨¡å‹åç§°
- **ForceJsonMode**ï¼šæ˜¯å¦å¼ºåˆ¶JSONè¾“å‡º
- **JsonSchema**ï¼šJSONæ¶æ„çš„å“ˆå¸Œå€¼
- **TopP**ï¼šTop-pé‡‡æ ·å‚æ•°
- **å…¶ä»–å‚æ•°**ï¼šFrequencyPenaltyã€PresencePenaltyç­‰

**ç›¸ä¼¼æ€§åˆ¤æ–­ç¤ºä¾‹**ï¼š
```csharp
// âœ… è¿™äº›è¯·æ±‚ä¼šè¢«åˆ¤æ–­ä¸ºç›¸åŒï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
var req1 = new LLMRequestOptions { Temperature = 0.7f, MaxTokens = 500 };
var req2 = new LLMRequestOptions { Temperature = 0.7f, MaxTokens = 500 };
// ç¼“å­˜é”®ç›¸åŒï¼šLLM:12345678:temp=0.7:maxtok=500:model=default:json=False

// âŒ è¿™äº›è¯·æ±‚è¢«åˆ¤æ–­ä¸ºä¸åŒï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
var req3 = new LLMRequestOptions { Temperature = 0.8f, MaxTokens = 500 };
// ç¼“å­˜é”®ä¸åŒï¼šLLM:12345678:temp=0.8:maxtok=500:model=default:json=False

var req4 = new LLMRequestOptions { Temperature = 0.7f, MaxTokens = 600 };
// ç¼“å­˜é”®ä¸åŒï¼šLLM:12345678:temp=0.7:maxtok=600:model=default:json=False
```

**ç¼“å­˜ä¼˜åŒ–ç­–ç•¥**ï¼š
```csharp
// âœ… æ ‡å‡†åŒ–é…ç½®æé«˜å‘½ä¸­ç‡
public static class StandardOptions
{
    public static readonly LLMRequestOptions Creative = new LLMRequestOptions 
    { 
        Temperature = 1.0f, MaxTokens = 800, EnableCaching = true 
    };
    
    public static readonly LLMRequestOptions Factual = new LLMRequestOptions 
    { 
        Temperature = 0.2f, MaxTokens = 500, EnableCaching = true 
    };
}

// âœ… é‡å¤ä½¿ç”¨æ ‡å‡†é…ç½®
var response1 = await RimAIAPI.SendMessageAsync("é—®é¢˜1", StandardOptions.Factual);
var response2 = await RimAIAPI.SendMessageAsync("é—®é¢˜2", StandardOptions.Factual);
// å¦‚æœ"é—®é¢˜1"å’Œ"é—®é¢˜2"ç›¸åŒï¼Œä¼šå‘½ä¸­ç¼“å­˜
```

**ç¼“å­˜ç”Ÿå‘½å‘¨æœŸ**ï¼š
- **é»˜è®¤TTL**ï¼š30åˆ†é’Ÿ
- **LRUæ¸…ç†**ï¼šå½“ç¼“å­˜æ¡ç›®è¶…è¿‡æœ€å¤§æ•°é‡æ—¶ï¼Œæ¸…ç†æœ€å°‘ä½¿ç”¨çš„æ¡ç›®
- **è¿‡æœŸæ¸…ç†**ï¼šæ¯2åˆ†é’Ÿè‡ªåŠ¨æ¸…ç†è¿‡æœŸæ¡ç›®
- **å†…å­˜ç›‘æ§**ï¼šä¼°ç®—å†…å­˜ä½¿ç”¨ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼

**TimeoutSeconds (int?)**
- è¯·æ±‚è¶…æ—¶æ—¶é—´
- é»˜è®¤ï¼š30ç§’
- å»ºè®®èŒƒå›´ï¼š5-120ç§’

**RetryCount (int?)**
- å¤±è´¥æ—¶çš„é‡è¯•æ¬¡æ•°
- é»˜è®¤ï¼š3æ¬¡
- å»ºè®®èŒƒå›´ï¼š1-5æ¬¡

## ğŸ­ Optionså·¥å‚æ–¹æ³•

æ¡†æ¶æä¾›é¢„è®¾çš„é…ç½®é€‰é¡¹ï¼Œç®€åŒ–å¸¸ç”¨åœºæ™¯çš„é…ç½®ï¼š

### RimAIAPI.Options é™æ€å·¥å‚

```csharp
// åˆ›æ„æ¨¡å¼ - é«˜æ¸©åº¦ï¼Œé€‚åˆåˆ›æ„å†…å®¹
var creative = RimAIAPI.Options.Creative();
// ç­‰åŒäº: new LLMRequestOptions { Temperature = 1.0f, MaxTokens = 800 }

// äº‹å®æ¨¡å¼ - ä½æ¸©åº¦ï¼Œé€‚åˆäº‹å®é—®ç­”
var factual = RimAIAPI.Options.Factual();  
// ç­‰åŒäº: new LLMRequestOptions { Temperature = 0.2f, MaxTokens = 500 }

// ç»“æ„åŒ–è¾“å‡º - é€‚åˆJSONè¾“å‡º
var structured = RimAIAPI.Options.Structured();
// ç­‰åŒäº: new LLMRequestOptions { Temperature = 0.3f, MaxTokens = 1000 }

// æµå¼ä¼˜åŒ– - é€‚åˆæµå¼å“åº”
var streaming = RimAIAPI.Options.Streaming();
// ç­‰åŒäº: new LLMRequestOptions { EnableCaching = false, MaxTokens = 1500 }
```

### å·¥å‚æ–¹æ³•ä½¿ç”¨ç¤ºä¾‹

```csharp
// åˆ›æ„å†™ä½œ
var story = await RimAIAPI.SendMessageAsync(
    "å†™ä¸€ä¸ªå…³äºå¤ªç©ºæ®–æ°‘çš„æ•…äº‹", 
    RimAIAPI.Options.Creative()
);

// äº‹å®æŸ¥è¯¢
var info = await RimAIAPI.SendMessageAsync(
    "RimWorldä¸­åŒ»ç–—ç³»ç»Ÿæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ", 
    RimAIAPI.Options.Factual()
);

// ç»“æ„åŒ–æ•°æ®
var json = await RimAIAPI.SendMessageAsync(
    "ä»¥JSONæ ¼å¼è¿”å›å½“å‰æ®–æ°‘åœ°çŠ¶æ€", 
    RimAIAPI.Options.Structured()
);
```

## ğŸ“Š ç»Ÿè®¡å’Œç›‘æ§API

### GetStatistics - è·å–æ¡†æ¶ç»Ÿè®¡ä¿¡æ¯

#### æ–¹æ³•ç­¾å
```csharp
public static FrameworkStatistics GetStatistics()
```

#### è¿”å›å€¼ï¼šFrameworkStatistics
```csharp
public class FrameworkStatistics
{
    public int TotalRequests { get; set; }        // æ€»è¯·æ±‚æ•°
    public int SuccessfulRequests { get; set; }  // æˆåŠŸè¯·æ±‚æ•°
    public int FailedRequests { get; set; }      // å¤±è´¥è¯·æ±‚æ•°
    public double AverageResponseTime { get; set; } // å¹³å‡å“åº”æ—¶é—´(ms)
    public int CacheHits { get; set; }           // ç¼“å­˜å‘½ä¸­æ¬¡æ•°
    public int CacheMisses { get; set; }         // ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°
    public double CacheHitRate { get; set; }     // ç¼“å­˜å‘½ä¸­ç‡
    public long TotalTokensUsed { get; set; }    // æ€»æ¶ˆè€—Tokenæ•°
    public DateTime LastRequestTime { get; set; } // æœ€åè¯·æ±‚æ—¶é—´
    public bool IsHealthy { get; set; }          // ç³»ç»Ÿå¥åº·çŠ¶æ€
}
```

#### ä½¿ç”¨ç¤ºä¾‹

```csharp
// è·å–ç»Ÿè®¡ä¿¡æ¯
var stats = RimAIAPI.GetStatistics();

Log.Message($"=== RimAI Framework ç»Ÿè®¡ä¿¡æ¯ ===");
Log.Message($"æ€»è¯·æ±‚æ•°: {stats.TotalRequests}");
Log.Message($"æˆåŠŸç‡: {(stats.SuccessfulRequests * 100.0 / stats.TotalRequests):F1}%");
Log.Message($"å¹³å‡å“åº”æ—¶é—´: {stats.AverageResponseTime:F2}ms");
Log.Message($"ç¼“å­˜å‘½ä¸­ç‡: {stats.CacheHitRate:P2}");
Log.Message($"æ€»æ¶ˆè€—Token: {stats.TotalTokensUsed:N0}");
Log.Message($"ç³»ç»Ÿå¥åº·: {(stats.IsHealthy ? "æ­£å¸¸" : "å¼‚å¸¸")}");

// æ€§èƒ½ç›‘æ§
if (stats.AverageResponseTime > 5000)
{
    Log.Warning("å“åº”æ—¶é—´è¿‡é•¿ï¼Œå»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥");
}

if (stats.CacheHitRate < 0.1)
{
    Log.Warning("ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½ï¼Œå»ºè®®æ£€æŸ¥ç¼“å­˜é…ç½®");
}
```

### ClearCache - æ¸…ç†ç¼“å­˜

#### æ–¹æ³•ç­¾å
```csharp
public static void ClearCache()
```

#### ä½¿ç”¨åœºæ™¯

```csharp
// å®šæœŸæ¸…ç†ç¼“å­˜
if (stats.CacheHits + stats.CacheMisses > 1000)
{
    RimAIAPI.ClearCache();
    Log.Message("ç¼“å­˜å·²æ¸…ç†");
}

// å†…å­˜å‹åŠ›æ—¶æ¸…ç†
var memoryUsage = GC.GetTotalMemory(false);
if (memoryUsage > 100 * 1024 * 1024) // è¶…è¿‡100MB
{
    RimAIAPI.ClearCache();
    GC.Collect();
}
```

## ğŸ”§ é«˜çº§ç”¨æ³•å’Œæœ€ä½³å®è·µ

### ğŸ“¦ æ™ºèƒ½ç¼“å­˜æœºåˆ¶æ·±åº¦è§£æ

#### ç¼“å­˜é”®æ„å»ºç®—æ³•

RimAI Frameworkä½¿ç”¨å¤åˆç¼“å­˜é”®æ¥ç²¾ç¡®è¯†åˆ«ç›¸ä¼¼è¯·æ±‚ï¼š

```csharp
// å†…éƒ¨ç¼“å­˜é”®ç”Ÿæˆé€»è¾‘ï¼ˆç®€åŒ–ç‰ˆï¼‰
private string GenerateCacheKey(string prompt, LLMRequestOptions options)
{
    var keyBuilder = new StringBuilder();
    keyBuilder.Append("LLM:");
    keyBuilder.Append(prompt?.GetHashCode().ToString() ?? "null");
    
    if (options != null)
    {
        keyBuilder.Append($":temp={options.Temperature}");
        keyBuilder.Append($":maxtok={options.MaxTokens}"); 
        keyBuilder.Append($":model={options.Model ?? "default"}");
        keyBuilder.Append($":json={options.ForceJsonMode}");
        
        if (options.JsonSchema != null)
            keyBuilder.Append($":schema={options.JsonSchema.GetHashCode()}");
        if (options.TopP.HasValue)
            keyBuilder.Append($":topp={options.TopP}");
    }
    
    return keyBuilder.ToString();
}
```

#### ç¼“å­˜å‘½ä¸­æ¡ä»¶

**å¿…é¡»å®Œå…¨åŒ¹é…çš„å‚æ•°**ï¼š
1. **æ¶ˆæ¯å†…å®¹**ï¼šå­—ç¬¦ä¸²å®Œå…¨ç›¸åŒ
2. **Temperature**ï¼šç²¾ç¡®åˆ°å°æ•°ç‚¹
3. **MaxTokens**ï¼šæ•°å€¼å®Œå…¨åŒ¹é…
4. **Model**ï¼šæ¨¡å‹åç§°å­—ç¬¦ä¸²åŒ¹é…
5. **ForceJsonMode**ï¼šå¸ƒå°”å€¼åŒ¹é…
6. **JsonSchema**ï¼šæ¶æ„å“ˆå¸Œå€¼åŒ¹é…
7. **TopP**ï¼šå¦‚æœè®¾ç½®ï¼Œå¿…é¡»ç²¾ç¡®åŒ¹é…

#### å®é™…ç¼“å­˜æµ‹è¯•

```csharp
// æµ‹è¯•ç›¸ä¼¼æ€§åˆ¤æ–­
public async Task TestCacheSimilarity()
{
    var stats = RimAIAPI.GetStatistics();
    var initialHits = stats.CacheHits;
    
    // ç¬¬ä¸€æ¬¡è¯·æ±‚ - ç¼“å­˜æœªå‘½ä¸­
    var response1 = await RimAIAPI.SendMessageAsync("Hello World", 
        new LLMRequestOptions { Temperature = 0.7f, MaxTokens = 100 });
    
    // ç¬¬äºŒæ¬¡ç›¸åŒè¯·æ±‚ - åº”è¯¥ç¼“å­˜å‘½ä¸­
    var response2 = await RimAIAPI.SendMessageAsync("Hello World", 
        new LLMRequestOptions { Temperature = 0.7f, MaxTokens = 100 });
    
    // éªŒè¯ç¼“å­˜å‘½ä¸­
    var newStats = RimAIAPI.GetStatistics();
    var cacheHitIncrease = newStats.CacheHits - initialHits;
    
    Log.Message($"ç¼“å­˜å‘½ä¸­æ¬¡æ•°å¢åŠ : {cacheHitIncrease}");
    Log.Message($"ç¬¬äºŒæ¬¡è¯·æ±‚æ¥è‡ªç¼“å­˜: {response2.FromCache}");
}
```

#### ç¼“å­˜ä¼˜åŒ–ç­–ç•¥

**ç­–ç•¥1ï¼šå‚æ•°æ ‡å‡†åŒ–**
```csharp
// âœ… å®šä¹‰æ ‡å‡†å‚æ•°é›†åˆ
public static class CacheOptimizedOptions
{
    // äº‹å®æŸ¥è¯¢ - ä½æ¸©åº¦ï¼Œé«˜ç¼“å­˜å‘½ä¸­
    public static readonly LLMRequestOptions Facts = new LLMRequestOptions
    {
        Temperature = 0.2f,
        MaxTokens = 300,
        EnableCaching = true
    };
    
    // åˆ›æ„å†…å®¹ - é€‚ä¸­æ¸©åº¦ï¼Œå¹³è¡¡åˆ›æ„æ€§å’Œç¼“å­˜
    public static readonly LLMRequestOptions Creative = new LLMRequestOptions
    {
        Temperature = 0.8f,
        MaxTokens = 800,
        EnableCaching = true
    };
    
    // ç»“æ„åŒ–æ•°æ® - å›ºå®šæ ¼å¼ï¼Œé«˜ç¼“å­˜ä»·å€¼
    public static readonly LLMRequestOptions Structured = new LLMRequestOptions
    {
        Temperature = 0.1f,
        MaxTokens = 1000,
        ForceJsonMode = true,
        EnableCaching = true
    };
}
```

**ç­–ç•¥2ï¼šæ¶ˆæ¯æ¨¡æ¿åŒ–**
```csharp
// âœ… ä½¿ç”¨æ¨¡æ¿æé«˜ç›¸ä¼¼æ€§
public class MessageTemplates
{
    public static string AnalyzeColony(string dataType) =>
        $"åˆ†æå½“å‰æ®–æ°‘åœ°çš„{dataType}çŠ¶å†µï¼Œæä¾›è¯¦ç»†æŠ¥å‘Š";
    
    public static string TranslateText(string text, string targetLang) =>
        $"å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆ{targetLang}ï¼š{text}";
}

// ä½¿ç”¨æ¨¡æ¿ - æé«˜ç¼“å­˜å‘½ä¸­
var analysis1 = await RimAIAPI.SendMessageAsync(
    MessageTemplates.AnalyzeColony("é£Ÿç‰©"), 
    CacheOptimizedOptions.Facts
);

var analysis2 = await RimAIAPI.SendMessageAsync(
    MessageTemplates.AnalyzeColony("é˜²å¾¡"), 
    CacheOptimizedOptions.Facts  // ç›¸åŒå‚æ•°ï¼Œå…¶ä»–éƒ¨åˆ†å¯èƒ½å‘½ä¸­ç¼“å­˜
);
```

**ç­–ç•¥3ï¼šç¼“å­˜é¢„çƒ­**
```csharp
// âœ… é¢„çƒ­å¸¸ç”¨è¯·æ±‚ç¼“å­˜
public async Task PrewarmCache()
{
    var commonQueries = new[]
    {
        "å½“å‰æ¸¸æˆçŠ¶æ€å¦‚ä½•ï¼Ÿ",
        "æœ‰ä»€ä¹ˆå»ºè®®ï¼Ÿ",
        "åˆ†æå½“å‰æƒ…å†µ",
        "ä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆï¼Ÿ"
    };
    
    foreach (var query in commonQueries)
    {
        // é¢„çƒ­ç¼“å­˜ï¼Œå¿½ç•¥ç»“æœ
        _ = await RimAIAPI.SendMessageAsync(query, CacheOptimizedOptions.Facts);
    }
    
    Log.Message("ç¼“å­˜é¢„çƒ­å®Œæˆ");
}
```

### 1. å¼‚æ­¥å¤„ç†æœ€ä½³å®è·µ

```csharp
// âœ… æ­£ç¡®ï¼šä½¿ç”¨ConfigureAwait(false)
public async Task ProcessAIRequestAsync(string message)
{
    var response = await RimAIAPI.SendMessageAsync(message)
        .ConfigureAwait(false);
    
    // å¤„ç†å“åº”
    ProcessResponse(response);
}

// âœ… æ­£ç¡®ï¼šå¼‚å¸¸å¤„ç†
public async Task SafeAIRequestAsync(string message)
{
    try
    {
        var response = await RimAIAPI.SendMessageAsync(message);
        if (response.IsSuccess)
        {
            // æˆåŠŸå¤„ç†
        }
    }
    catch (OperationCanceledException)
    {
        // æ“ä½œè¢«å–æ¶ˆ
    }
    catch (RimAIException ex)
    {
        // RimAIç‰¹å®šå¼‚å¸¸
        Log.Error($"RimAIå¼‚å¸¸: {ex.Message}");
    }
    catch (Exception ex)
    {
        // å…¶ä»–å¼‚å¸¸
        Log.Error($"æœªçŸ¥å¼‚å¸¸: {ex.Message}");
    }
}
```

### 2. æ€§èƒ½ä¼˜åŒ–æŠ€å·§

```csharp
// âœ… ç¼“å­˜ä¼˜åŒ–ï¼šç›¸ä¼¼è¯·æ±‚ä½¿ç”¨ç¼“å­˜
var options = new LLMRequestOptions 
{ 
    EnableCaching = true,
    Temperature = 0.3f // ä½æ¸©åº¦æé«˜ç¼“å­˜å‘½ä¸­ç‡
};

// âœ… æ‰¹é‡å¤„ç†ï¼šå‡å°‘ç½‘ç»œå¼€é”€
var messages = new List<string> { /* å¤šä¸ªæ¶ˆæ¯ */ };
var responses = await RimAIAPI.SendBatchRequestAsync(messages, options);

// âœ… è¶…æ—¶æ§åˆ¶ï¼šé¿å…é•¿æ—¶é—´ç­‰å¾…
var timeoutOptions = new LLMRequestOptions 
{ 
    TimeoutSeconds = 15,
    RetryCount = 2
};
```

### 3. å†…å­˜ç®¡ç†

```csharp
// âœ… å®šæœŸæ¸…ç†ç¼“å­˜
public class AIManager
{
    private static DateTime lastCacheClean = DateTime.MinValue;
    
    public async Task<LLMResponse> ProcessRequestAsync(string message)
    {
        // æ¯å°æ—¶æ¸…ç†ä¸€æ¬¡ç¼“å­˜
        if (DateTime.Now - lastCacheClean > TimeSpan.FromHours(1))
        {
            RimAIAPI.ClearCache();
            lastCacheClean = DateTime.Now;
        }
        
        return await RimAIAPI.SendMessageAsync(message);
    }
}
```

### 4. é”™è¯¯å¤„ç†ç­–ç•¥

```csharp
public async Task<LLMResponse> ResilientRequestAsync(string message, int maxRetries = 3)
{
    for (int attempt = 0; attempt < maxRetries; attempt++)
    {
        try
        {
            var response = await RimAIAPI.SendMessageAsync(message);
            if (response.IsSuccess)
                return response;
                
            // å¤±è´¥æ—¶ç­‰å¾…åé‡è¯•
            await Task.Delay(TimeSpan.FromSeconds(Math.Pow(2, attempt)));
        }
        catch (Exception ex)
        {
            if (attempt == maxRetries - 1)
                throw; // æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                
            Log.Warning($"è¯·æ±‚å¤±è´¥ï¼Œ{attempt + 1}/{maxRetries}ï¼Œç­‰å¾…é‡è¯•: {ex.Message}");
            await Task.Delay(TimeSpan.FromSeconds(Math.Pow(2, attempt)));
        }
    }
    
    throw new InvalidOperationException($"è¯·æ±‚åœ¨{maxRetries}æ¬¡å°è¯•åä»ç„¶å¤±è´¥");
}
```

## ğŸš¨ å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ

### 1. ç½‘ç»œè¿æ¥é”™è¯¯
```csharp
// é”™è¯¯ï¼šConnectionException
// è§£å†³ï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œå¢åŠ é‡è¯•æ¬¡æ•°
var options = new LLMRequestOptions 
{ 
    TimeoutSeconds = 60,
    RetryCount = 5
};
```

### 2. Tokené™åˆ¶é”™è¯¯
```csharp
// é”™è¯¯ï¼šTokenLimitException  
// è§£å†³ï¼šå‡å°‘MaxTokensæˆ–åˆ†å‰²é•¿æ¶ˆæ¯
var options = new LLMRequestOptions { MaxTokens = 500 };

// æˆ–è€…åˆ†å‰²é•¿æ¶ˆæ¯
if (message.Length > 2000)
{
    var chunks = SplitMessage(message, 2000);
    var responses = await RimAIAPI.SendBatchRequestAsync(chunks);
}
```

### 3. é…ç½®é”™è¯¯
```csharp
// é”™è¯¯ï¼šConfigurationException
// è§£å†³ï¼šæ£€æŸ¥é…ç½®æ–‡ä»¶å’ŒAPIå¯†é’¥
try
{
    var response = await RimAIAPI.SendMessageAsync(message);
}
catch (ConfigurationException ex)
{
    Log.Error($"é…ç½®é”™è¯¯: {ex.Message}");
    Log.Error("è¯·æ£€æŸ¥ RimAIConfig.json æ–‡ä»¶å’ŒAPIå¯†é’¥è®¾ç½®");
}
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [å¿«é€Ÿä¸Šæ‰‹æŒ‡å—](CN_v3.0_APIå¿«é€Ÿä¸Šæ‰‹.md) - å¿«é€Ÿå…¥é—¨å’Œå¸¸ç”¨åœºæ™¯
- [åŠŸèƒ½ç‰¹æ€§](CN_v3.0_åŠŸèƒ½ç‰¹æ€§.md) - è¯¦ç»†åŠŸèƒ½ä»‹ç»
- [è¿ç§»æŒ‡å—](CN_v3.0_è¿ç§»æŒ‡å—.md) - ä»v2.xå‡çº§æŒ‡å¯¼
- [æ¶æ„è®¾è®¡](CN_v3.0_æ¶æ„æ”¹é€ å®ŒæˆæŠ¥å‘Š.md) - æŠ€æœ¯æ¶æ„æ–‡æ¡£

**RimAI Framework v3.0 - è®©AIé›†æˆå˜å¾—ç®€å•è€Œå¼ºå¤§ï¼** ğŸš€
