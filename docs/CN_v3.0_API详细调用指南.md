n# ğŸ“˜ RimAI Framework v3.0 APIè¯¦ç»†è°ƒç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›RimAI Framework v3.0æ‰€æœ‰APIçš„è¯¦ç»†è°ƒç”¨æ–¹æ³•ã€å‚æ•°è¯´æ˜å’Œé«˜çº§ç”¨æ³•ã€‚é€‚åˆéœ€è¦æ·±å…¥äº†è§£æ¡†æ¶åŠŸèƒ½çš„å¼€å‘è€…ã€‚

## ğŸ¯ æ ¸å¿ƒAPIç±»ï¼šRimAIAPI

`RimAIAPI` æ˜¯æ¡†æ¶çš„ç»Ÿä¸€å…¥å£ç‚¹ï¼Œæä¾›æ‰€æœ‰ä¸»è¦åŠŸèƒ½çš„é™æ€æ–¹æ³•ã€‚

### å‘½åç©ºé—´
```csharp
using RimAI.Framework.API;
using RimAI.Framework.LLM.Models;
```

## 1. åŸºç¡€API vs é«˜çº§API

ä¸ºäº†æ»¡è¶³ä¸åŒå¼€å‘è€…çš„éœ€æ±‚ï¼ŒRimAI v3.0 æä¾›äº†ä¸¤ç§æ ¸å¿ƒAPIï¼š

- **åŸºç¡€API (`SendMessageAsync`)**: 
  - **è¿”å›**: `string`
  - **ç‰¹ç‚¹**: ç®€å•ã€ç›´æ¥ï¼Œå¿«é€Ÿè·å–æ–‡æœ¬ç»“æœã€‚
  - **é€‚ç”¨åœºæ™¯**: é€‚ç”¨äºä¸å…³å¿ƒé”™è¯¯ç»†èŠ‚ã€Tokenæ¶ˆè€—ç­‰å…ƒæ•°æ®çš„ç®€å•è¯·æ±‚ã€‚
  
- **é«˜çº§API (`SendRequestAsync`)**: 
  - **è¿”å›**: `LLMResponse` å¯¹è±¡
  - **ç‰¹ç‚¹**: åŠŸèƒ½å¼ºå¤§ï¼Œæä¾›è¯¦ç»†çš„æˆåŠŸ/å¤±è´¥çŠ¶æ€ã€é”™è¯¯ä¿¡æ¯å’Œå…ƒæ•°æ®ã€‚
  - **é€‚ç”¨åœºæ™¯**: æ¨èç”¨äºéœ€è¦å¯é é”™è¯¯å¤„ç†ã€è®¿é—®å“åº”å…ƒæ•°æ®ï¼ˆå¦‚Tokenä½¿ç”¨æƒ…å†µï¼‰çš„ç”Ÿäº§çº§åŠŸèƒ½ã€‚

---

## 2. SendMessageAsync - åŸºç¡€æ¶ˆæ¯å‘é€ (è¿”å› string)

æ­¤æ–¹æ³•æ˜¯ä¸AIè¿›è¡Œç®€å•äº¤äº’çš„æœ€å¿«æ–¹å¼ã€‚å®ƒç›´æ¥è¿”å›AIçš„å“åº”æ–‡æœ¬ï¼Œå¦‚æœå‘ç”Ÿé”™è¯¯åˆ™è¿”å›`null`ã€‚

#### æ–¹æ³•ç­¾å
```csharp
public static async Task<string> SendMessageAsync(
    string message, 
    LLMRequestOptions options = null
)
```

#### å‚æ•°è¯¦è§£

**message (string, å¿…éœ€)**
- å‘é€ç»™LLMçš„æ¶ˆæ¯å†…å®¹
- æ”¯æŒå¤šè¡Œæ–‡æœ¬å’Œç‰¹æ®Šå­—ç¬¦
- å»ºè®®é•¿åº¦ï¼š1-8000å­—ç¬¦

**options (LLMRequestOptions, å¯é€‰)**
- è¯·æ±‚é…ç½®é€‰é¡¹ï¼Œnullæ—¶ä½¿ç”¨é»˜è®¤é…ç½®
- è¯¦ç»†å‚æ•°è§ [LLMRequestOptions](#llmrequestoptions-è¯¦ç»†å‚æ•°)

#### è¿”å›å€¼ï¼šstring
- è¿”å›AIç”Ÿæˆçš„å“åº”å†…å®¹å­—ç¬¦ä¸²
- å¦‚æœè¯·æ±‚å¤±è´¥ï¼Œè¿”å›null
- æ¡†æ¶å†…éƒ¨å·²å¤„ç†é”™è¯¯å’Œé‡è¯•æœºåˆ¶

#### ä½¿ç”¨ç¤ºä¾‹

**åŸºç¡€è°ƒç”¨**
```csharp
// æœ€ç®€å•çš„è°ƒç”¨æ–¹å¼
var response = await RimAIAPI.SendMessageAsync("Hello, AI!");
if (!string.IsNullOrEmpty(response))
{
    Log.Message($"AIå›å¤: {response}");
}
```

**å¸¦å‚æ•°è°ƒç”¨**
```csharp
// ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
var options = new LLMRequestOptions
{
    Temperature = 0.8f,
    MaxTokens = 500,
    EnableCaching = true
};

var response = await RimAIAPI.SendMessageAsync(
    "å†™ä¸€ä¸ªå…³äºRimWorldçš„çŸ­æ•…äº‹", 
    options
);
```

**é”™è¯¯å¤„ç†**
```csharp
try
{
    var response = await RimAIAPI.SendMessageAsync("ä½ å¥½");
    if (string.IsNullOrEmpty(response))
    {
        Log.Error("è¯·æ±‚å¤±è´¥ï¼šæœªæ”¶åˆ°å“åº”");
        return;
    }
    
    // å¤„ç†æˆåŠŸå“åº”
    ProcessResponse(response);
}
catch (RimAIException ex)
{
    Log.Error($"RimAIå¼‚å¸¸: {ex.Message}");
}
catch (Exception ex)
{
    Log.Error($"æœªçŸ¥é”™è¯¯: {ex.Message}");
}
```

### 2. SendMessageStreamAsync - æµå¼æ¶ˆæ¯å‘é€

#### æ–¹æ³•ç­¾å
```csharp
public static async Task SendMessageStreamAsync(
    string message,
    Action<string> onChunkReceived,
    LLMRequestOptions options = null,
    CancellationToken cancellationToken = default
)
```

#### å‚æ•°è¯¦è§£

**message (string, å¿…éœ€)**
- å‘é€ç»™LLMçš„æ¶ˆæ¯å†…å®¹

**onChunkReceived (Action<string>, å¿…éœ€)**
- æ¥æ”¶å“åº”å—çš„å›è°ƒå‡½æ•°
- æ¯æ¬¡æ”¶åˆ°æ–°çš„å“åº”ç‰‡æ®µæ—¶è§¦å‘
- å‚æ•°æ˜¯å“åº”å†…å®¹çš„ç‰‡æ®µ

**options (LLMRequestOptions, å¯é€‰)**
- è¯·æ±‚é…ç½®é€‰é¡¹

**cancellationToken (CancellationToken, å¯é€‰)**
- ç”¨äºå–æ¶ˆé•¿æ—¶é—´è¿è¡Œçš„è¯·æ±‚

#### ä½¿ç”¨ç¤ºä¾‹

**åŸºç¡€æµå¼è°ƒç”¨**
```csharp
var fullResponse = new StringBuilder();

await RimAIAPI.SendMessageStreamAsync(
    "è¯¦ç»†è§£é‡ŠRimWorldçš„æˆ˜æ–—ç³»ç»Ÿ",
    chunk => {
        // å®æ—¶æ¥æ”¶å“åº”ç‰‡æ®µ
        Log.Message($"æ”¶åˆ°: {chunk}");
        fullResponse.Append(chunk);
    }
);

Log.Message($"å®Œæ•´å“åº”: {fullResponse.ToString()}");
```

**å¸¦å–æ¶ˆåŠŸèƒ½çš„æµå¼è°ƒç”¨**
```csharp
var cts = new CancellationTokenSource();
var responseBuilder = new StringBuilder();

// è®¾ç½®5ç§’è¶…æ—¶
cts.CancelAfter(TimeSpan.FromSeconds(5));

try
{
    await RimAIAPI.SendMessageStreamAsync(
        "å†™ä¸€ç¯‡é•¿ç¯‡å°è¯´",
        chunk => {
            responseBuilder.Append(chunk);
            
            // å¯ä»¥åœ¨å›è°ƒä¸­æ£€æŸ¥æ¡ä»¶å¹¶å–æ¶ˆ
            if (responseBuilder.Length > 1000)
            {
                cts.Cancel();
            }
        },
        options: new LLMRequestOptions { Temperature = 0.9f },
        cancellationToken: cts.Token
    );
}
catch (OperationCanceledException)
{
    Log.Message("è¯·æ±‚è¢«å–æ¶ˆ");
}
```

**å®æ—¶UIæ›´æ–°ç¤ºä¾‹**
```csharp
var dialog = Find.WindowStack.WindowOfType<MyAIDialog>();

await RimAIAPI.SendMessageStreamAsync(
    userInput,
    chunk => {
        // åœ¨ä¸»çº¿ç¨‹æ›´æ–°UI
        if (Current.ProgramState == ProgramState.Playing)
        {
            dialog?.UpdateResponseText(chunk);
        }
    },
    new LLMRequestOptions { EnableCaching = false }
);
```

### 3. SendRequestAsync - é«˜çº§æ¶ˆæ¯å‘é€ (è¿”å› LLMResponse)

æ­¤æ–¹æ³•æä¾›äº†æ›´å¼ºå¤§çš„åŠŸèƒ½å’Œæ›´ç²¾ç»†çš„æ§åˆ¶ï¼Œè¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰å“åº”ç»†èŠ‚çš„`LLMResponse`å¯¹è±¡ã€‚**è¿™æ˜¯æ¨èç”¨äºå¤§å¤šæ•°ç”Ÿäº§çº§åŠŸèƒ½çš„æ–¹æ³•ã€‚**

#### æ–¹æ³•ç­¾å
```csharp
public static async Task<LLMResponse> SendRequestAsync(
    string prompt,
    LLMRequestOptions options = null,
    CancellationToken cancellationToken = default
)
```

#### è¿”å›å€¼ï¼šLLMResponse

`LLMResponse` å¯¹è±¡åŒ…å«äº†æ‰€æœ‰å…³äºè¯·æ±‚å“åº”çš„è¯¦ç»†ä¿¡æ¯ï¼š
```csharp
public class LLMResponse
{
    // æ ¸å¿ƒå†…å®¹
    public string Content { get; }           // æå–å‡ºçš„ä¸»è¦å“åº”æ–‡æœ¬
    public List<ToolCall> ToolCalls { get; } // AIè¯·æ±‚çš„å·¥å…·è°ƒç”¨åˆ—è¡¨

    // çŠ¶æ€ä¸é”™è¯¯å¤„ç†
    public bool IsSuccess { get; }           // è¯·æ±‚æ˜¯å¦æˆåŠŸ
    public string ErrorMessage { get; }     // å¤±è´¥æ—¶çš„è¯¦ç»†é”™è¯¯ä¿¡æ¯

    // å…ƒæ•°æ®
    public string Id { get; set; }              // å“åº”çš„å”¯ä¸€ID
    public string Model { get; set; }           // ä½¿ç”¨çš„æ¨¡å‹åç§°
    public Usage Usage { get; set; }           // Tokenä½¿ç”¨æƒ…å†µç»Ÿè®¡
    public string RequestId { get; }         // å†…éƒ¨è¯·æ±‚ID
}

public class Usage
{
    public int PromptTokens { get; set; }     // è¾“å…¥çš„Tokenæ•°
    public int CompletionTokens { get; set; } // è¾“å‡ºçš„Tokenæ•°
    public int TotalTokens { get; set; }      // æ€»Tokenæ•°
}
```

#### ä½¿ç”¨ç¤ºä¾‹

**å¯é çš„è¯·æ±‚ä¸é”™è¯¯å¤„ç†**
```csharp
var response = await RimAIAPI.SendRequestAsync("ç”Ÿæˆä¸€ä¸ªå…³äºå¤ªç©ºå•†èˆ¹çš„èƒŒæ™¯æ•…äº‹");

if (response.IsSuccess)
{
    Log.Message($"æˆåŠŸï¼AIå›å¤: {response.Content}");
    
    // ä½ è¿˜å¯ä»¥æ£€æŸ¥Tokenä½¿ç”¨æƒ…å†µ
    if (response.Usage != null)
    {
        Log.Message($"æœ¬æ¬¡è¯·æ±‚æ¶ˆè€—äº† {response.Usage.TotalTokens} ä¸ªTokenã€‚");
    }
}
else
{
    // ç²¾ç¡®åœ°çŸ¥é“é”™è¯¯åŸå› 
    Log.Error($"AIè¯·æ±‚å¤±è´¥: {response.ErrorMessage}");
}
```

---

### 4. SendBatchRequestAsync - æ‰¹é‡è¯·æ±‚å¤„ç†

#### æ–¹æ³•ç­¾å
```csharp
public static async Task<List<string>> SendBatchRequestAsync(
    List<string> messages,
    LLMRequestOptions options = null
)
```

#### å‚æ•°è¯¦è§£

**messages (List<string>, å¿…éœ€)**
- è¦æ‰¹é‡å¤„ç†çš„æ¶ˆæ¯åˆ—è¡¨
- å»ºè®®æ‰¹é‡å¤§å°ï¼š1-10ä¸ªæ¶ˆæ¯
- æ¡†æ¶ä¼šè‡ªåŠ¨ä¼˜åŒ–å¹¶å‘å¤„ç†

**options (LLMRequestOptions, å¯é€‰)**
- åº”ç”¨äºæ‰€æœ‰è¯·æ±‚çš„é…ç½®é€‰é¡¹

#### è¿”å›å€¼ï¼šList<string>
- è¿”å›å“åº”å†…å®¹å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œé¡ºåºä¸è¾“å…¥æ¶ˆæ¯å¯¹åº”
- å¤±è´¥çš„è¯·æ±‚åœ¨åˆ—è¡¨ä¸­å¯¹åº”ä½ç½®ä¸ºnull
- å³ä½¿æŸä¸ªè¯·æ±‚å¤±è´¥ï¼Œå…¶ä»–è¯·æ±‚ä»ä¼šç»§ç»­å¤„ç†

#### ä½¿ç”¨ç¤ºä¾‹

**æ‰¹é‡ç¿»è¯‘**
```csharp
var texts = new List<string>
{
    "Hello World",
    "Good Morning", 
    "How are you?",
    "Thank you"
};

var responses = await RimAIAPI.SendBatchRequestAsync(
    texts.Select(t => $"å°†ä»¥ä¸‹è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡ï¼š{t}").ToList(),
    new LLMRequestOptions { Temperature = 0.3f }
);

for (int i = 0; i < responses.Count; i++)
{
    if (responses[i].IsSuccess)
    {
        Log.Message($"{texts[i]} -> {responses[i].Content}");
    }
    else
    {
        Log.Error($"ç¿»è¯‘å¤±è´¥: {texts[i]} - {responses[i].ErrorMessage}");
    }
}
```

**æ‰¹é‡æ•°æ®åˆ†æ**
```csharp
var dataQueries = new List<string>
{
    "åˆ†æå½“å‰æ®–æ°‘åœ°çš„é£Ÿç‰©çŠ¶å†µ",
    "è¯„ä¼°æ®–æ°‘åœ°çš„é˜²å¾¡èƒ½åŠ›", 
    "æ£€æŸ¥æ®–æ°‘åœ°çš„å¿ƒæƒ…çŠ¶æ€",
    "ç»Ÿè®¡æ®–æ°‘åœ°çš„èµ„æºæƒ…å†µ"
};

var options = new LLMRequestOptions
{
    MaxTokens = 300,
    Temperature = 0.5f,
    EnableCaching = true
};

var reports = await RimAIAPI.SendBatchRequestAsync(dataQueries, options);

// å¹¶è¡Œå¤„ç†ç»“æœ
Parallel.ForEach(reports.Where(r => !string.IsNullOrEmpty(r)), response => {
    ProcessAnalysisReport(response);
});
```

---

### 5. GetFunctionCallAsync - è·å–å‡½æ•°è°ƒç”¨å»ºè®®

æ­¤é«˜çº§APIå…è®¸ä½ å‘æ¨¡å‹æä¾›ä¸€ç³»åˆ—ä½ å®šä¹‰çš„å·¥å…·ï¼ˆå‡½æ•°ï¼‰ï¼Œå¹¶è®©æ¨¡å‹æ ¹æ®ç”¨æˆ·çš„`prompt`æ™ºèƒ½åœ°å†³å®šè°ƒç”¨å“ªä¸ªå·¥å…·ï¼Œä»¥åŠä½¿ç”¨ä»€ä¹ˆå‚æ•°ã€‚è¿™ä½¿å¾—æ„å»ºèƒ½å¤Ÿä¸æ¸¸æˆä¸–ç•Œæˆ–å…¶ä»–ç³»ç»Ÿè¿›è¡Œå®é™…äº¤äº’çš„å¤æ‚AIä»£ç†æˆä¸ºå¯èƒ½ã€‚

**æ ¸å¿ƒæ€æƒ³**ï¼šä½ å®šä¹‰å·¥å…·ï¼ŒAIå†³å®šä½•æ—¶ä»¥åŠå¦‚ä½•ä½¿ç”¨å®ƒä»¬ã€‚

#### æ–¹æ³•ç­¾å
```csharp
// æ³¨æ„ï¼šä¸ºé¿å…ä¸Verse.Toolå†²çªï¼Œè¯·ä½¿ç”¨usingåˆ«å
using AITool = RimAI.Framework.LLM.Models.Tool;

public static async Task<List<FunctionCallResult>> GetFunctionCallAsync(
    string prompt,
    List<AITool> tools,
    CancellationToken cancellationToken = default
)
```

#### å‚æ•°è¯¦è§£

**prompt (string, å¿…éœ€)**
- ç”¨æˆ·çš„è¾“å…¥ï¼Œæ¨¡å‹å°†åŸºäºæ­¤å†…å®¹å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·ã€‚

**tools (List<AITool>, å¿…éœ€)**
- ä½ æä¾›ç»™æ¨¡å‹çš„ä¸€ç³»åˆ—å¯ç”¨å·¥å…·ã€‚
- è¿™æ˜¯ä¸€ä¸ªå…³é”®å‚æ•°ï¼Œå®šä¹‰äº†æ¨¡å‹çš„èƒ½åŠ›è¾¹ç•Œã€‚

**cancellationToken (CancellationToken, å¯é€‰)**
- ç”¨äºå–æ¶ˆè¯·æ±‚ã€‚

#### è¿”å›å€¼ï¼š`List<FunctionCallResult>`
- ä¸€ä¸ªåŒ…å«é›¶ä¸ªæˆ–å¤šä¸ª`FunctionCallResult`å¯¹è±¡çš„åˆ—è¡¨ã€‚
- å¦‚æœæ¨¡å‹è®¤ä¸ºä¸éœ€è¦è°ƒç”¨ä»»ä½•å·¥å…·ï¼Œæˆ–è€…å‘ç”Ÿé”™è¯¯ï¼Œè¿”å›`null`ã€‚
- `FunctionCallResult`çš„ç»“æ„å¦‚ä¸‹ï¼š
```csharp
public class FunctionCallResult
{
    public string ToolId { get; set; }       // å·¥å…·è°ƒç”¨çš„å”¯ä¸€ID
    public string FunctionName { get; set; } // å»ºè®®è°ƒç”¨çš„å‡½æ•°å
    public string Arguments { get; set; }    // JSONæ ¼å¼çš„å‡½æ•°å‚æ•°å­—ç¬¦ä¸²
}
```

#### æ•°æ®æ¨¡å‹ï¼šå®šä¹‰ä¸€ä¸ªå·¥å…· (Tool)
ä¸€ä¸ªå·¥å…·ç”±å…¶ç±»å‹ï¼ˆå§‹ç»ˆæ˜¯ "function"ï¼‰å’Œä¸€ä¸ªå‡½æ•°å®šä¹‰ç»„æˆã€‚

```csharp
// AITool, FunctionDefinitionç­‰æ¨¡å‹å‡åœ¨
// RimAI.Framework.LLM.Models å‘½åç©ºé—´ä¸‹

var myTool = new AITool
{
    Type = "function",
    Function = new FunctionDefinition
    {
        Name = "your_function_name", // å‡½æ•°çš„å”¯ä¸€åç§°
        Description = "è¿™ä¸ªå‡½æ•°æ˜¯åšä»€ä¹ˆçš„æ¸…æ™°æè¿°", // æ¨¡å‹ä¼šæ ¹æ®æè¿°æ¥å†³å®šä½•æ—¶ä½¿ç”¨å®ƒ
        Parameters = new FunctionParameters
        {
            Type = "object",
            Properties = new Dictionary<string, ParameterProperty>
            {
                // å®šä¹‰ä½ çš„å‚æ•°
                { "param1", new ParameterProperty { Type = "string", Description = "å‚æ•°1çš„æè¿°" } },
                { "param2", new ParameterProperty { Type = "number", Description = "å‚æ•°2çš„æè¿°" } }
            },
            Required = new List<string> { "param1" } // å¿…éœ€çš„å‚æ•°åˆ—è¡¨
        }
    }
};
```

#### ä½¿ç”¨ç¤ºä¾‹ï¼šæ„å»ºä¸€ä¸ªæ¸¸æˆå†…è®¡ç®—å™¨

å‡è®¾æˆ‘ä»¬æƒ³è®©AIèƒ½å¤Ÿå›ç­”æ•°å­¦é—®é¢˜ï¼Œä½†æˆ‘ä»¬ä¸å¸Œæœ›å®ƒè‡ªå·±è®¡ç®—ï¼Œè€Œæ˜¯è°ƒç”¨æˆ‘ä»¬æ¸¸æˆä¸­çš„ç²¾ç¡®è®¡ç®—æ–¹æ³•ã€‚

**ç¬¬ä¸€æ­¥ï¼šå®šä¹‰å·¥å…·**
```csharp
using AITool = RimAI.Framework.LLM.Models.Tool;
using RimAI.Framework.LLM.Models; // å¼•å…¥FunctionDefinitionç­‰æ¨¡å‹

// åˆ›å»ºä¸€ä¸ªä¹˜æ³•å·¥å…·
var multiplyTool = new AITool
{
    Type = "function",
    Function = new FunctionDefinition
    {
        Name = "multiply",
        Description = "è®¡ç®—ä¸¤ä¸ªæ•°çš„ä¹˜ç§¯",
        Parameters = new FunctionParameters
        {
            Type = "object",
            Properties = new Dictionary<string, ParameterProperty>
            {
                { "a", new ParameterProperty { Type = "number", Description = "ç¬¬ä¸€ä¸ªæ•°å­—" } },
                { "b", new ParameterProperty { Type = "number", Description = "ç¬¬äºŒä¸ªæ•°å­—" } }
            },
            Required = new List<string> { "a", "b" }
        }
    }
};

var tools = new List<AITool> { multiplyTool };
```

**ç¬¬äºŒæ­¥ï¼šè°ƒç”¨API**
```csharp
var prompt = "è¯·å¸®æˆ‘è®¡ç®—ä¸€ä¸‹ï¼Œå¦‚æœæˆ‘æœ‰128ä¸ªå•ä½çš„ç™½é“¶ï¼Œæ¯ä¸ªå•ä½ä»·å€¼5.5å…ƒï¼Œæ€»ä»·å€¼æ˜¯å¤šå°‘ï¼Ÿ";

List<FunctionCallResult> suggestedCalls = await RimAIAPI.GetFunctionCallAsync(prompt, tools);
```

**ç¬¬ä¸‰æ­¥ï¼šå¤„ç†ç»“æœå¹¶æ‰§è¡Œæœ¬åœ°æ–¹æ³•**
```csharp
if (suggestedCalls != null && suggestedCalls.Count > 0)
{
    foreach (var call in suggestedCalls)
    {
        Log.Message($"AIå»ºè®®è°ƒç”¨å‡½æ•°: {call.FunctionName}");
        Log.Message($"å‚æ•° (JSON): {call.Arguments}");

        if (call.FunctionName == "multiply")
        {
            // ä½ éœ€è¦ä¸€ä¸ªç±»æ¥ååºåˆ—åŒ–å‚æ•°
            // ä¾‹å¦‚ï¼špublic class MultiplyArgs { public double a { get; set; } public double b { get; set; } }
            var args = JsonConvert.DeserializeObject<MultiplyArgs>(call.Arguments);
            
            // æ‰§è¡Œä½ è‡ªå·±çš„æœ¬åœ°C#æ–¹æ³•
            double result = MyLocalCalculator.Multiply(args.a, args.b);
            
            Log.Message($"æœ¬åœ°è®¡ç®—ç»“æœ: {result}");
            
            // åç»­æ­¥éª¤ï¼šä½ å¯ä»¥å°†æ‰§è¡Œç»“æœå†å‘ç»™AIï¼Œè®©å®ƒä»¥è‡ªç„¶è¯­è¨€å›å¤ç”¨æˆ·ã€‚
        }
    }
}
else
{
    Log.Message("AIæ²¡æœ‰å»ºè®®è°ƒç”¨ä»»ä½•å‡½æ•°ã€‚");
}
```

#### å®Œæ•´ç¤ºä¾‹ï¼šå¤šå·¥å…·é€‰æ‹©

è¿™ä¸ªæ›´å¤æ‚çš„ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•å®šä¹‰å¤šä¸ªå·¥å…·ï¼Œå¹¶è®©AIæ ¹æ®ä¸åŒçš„ç”¨æˆ·é—®é¢˜è‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„ä¸€ä¸ªã€‚

**ç¬¬ä¸€æ­¥ï¼šå®šä¹‰æ‰€æœ‰å·¥å…·**
```csharp
using AITool = RimAI.Framework.LLM.Models.Tool;
using RimAI.Framework.LLM.Models;
using System.Collections.Generic;

var tools = new List<AITool>
{
    // å·¥å…·1: ä¹˜æ³•
    new AITool { Function = new FunctionDefinition {
        Name = "mul",
        Description = "è®¡ç®—ä¸¤ä¸ªæ•°çš„ä¹˜ç§¯",
        Parameters = new FunctionParameters {
            Properties = new Dictionary<string, ParameterProperty> {
                { "a", new ParameterProperty { Type = "number", Description = "ç¬¬ä¸€ä¸ªæ•°å­—" } },
                { "b", new ParameterProperty { Type = "number", Description = "ç¬¬äºŒä¸ªæ•°å­—" } }
            },
            Required = new List<string> { "a", "b" }
        }
    }},
    // å·¥å…·2: æ¯”è¾ƒå¤§å°
    new AITool { Function = new FunctionDefinition {
        Name = "compare",
        Description = "æ¯”è¾ƒä¸¤ä¸ªæ•°å­—çš„å¤§å°",
        Parameters = new FunctionParameters {
            Properties = new Dictionary<string, ParameterProperty> {
                { "a", new ParameterProperty { Type = "number", Description = "ç¬¬ä¸€ä¸ªæ•°å­—" } },
                { "b", new ParameterProperty { Type = "number", Description = "ç¬¬äºŒä¸ªæ•°å­—" } }
            },
            Required = new List<string> { "a", "b" }
        }
    }},
    // å·¥å…·3: ç»Ÿè®¡å­—ç¬¦
    new AITool { Function = new FunctionDefinition {
        Name = "count_letter_in_string",
        Description = "ç»Ÿè®¡ä¸€ä¸ªå­—ç¬¦ä¸²ä¸­æŸä¸ªå­—æ¯å‡ºç°çš„æ¬¡æ•°",
        Parameters = new FunctionParameters {
            Properties = new Dictionary<string, ParameterProperty> {
                { "a", new ParameterProperty { Type = "string", Description = "æºå­—ç¬¦ä¸²" } },
                { "b", new ParameterProperty { Type = "string", Description = "è¦è®¡æ•°çš„å­—æ¯" } }
            },
            Required = new List<string> { "a", "b" }
        }
    }}
};
```

**ç¬¬äºŒæ­¥ï¼šé’ˆå¯¹ä¸åŒé—®é¢˜è°ƒç”¨API**
```csharp
var prompts = new List<string>
{
    "ç”¨ä¸­æ–‡å›ç­”ï¼šstrawberryä¸­æœ‰å¤šå°‘ä¸ªr?",
    "ç”¨ä¸­æ–‡å›ç­”ï¼š9.11å’Œ9.9ï¼Œå“ªä¸ªå°?"
};

foreach (var prompt in prompts)
{
    Log.Message($"\n--- å¤„ç†æ–°é—®é¢˜: {prompt} ---");
    var suggestedCalls = await RimAIAPI.GetFunctionCallAsync(prompt, tools);

    if (suggestedCalls != null && suggestedCalls.Count > 0)
    {
        var call = suggestedCalls.First();
        Log.Message($"AIå»ºè®®è°ƒç”¨: '{call.FunctionName}'");
        Log.Message($"å‚æ•°: {call.Arguments}");
        
        // åœ¨è¿™é‡Œï¼Œä½ å¯ä»¥æ ¹æ®call.FunctionNameè°ƒç”¨ä½ æœ¬åœ°çš„C#æ–¹æ³•
        // å¹¶ç”¨è¿”å›çš„ç»“æœè¿›è¡Œä¸‹ä¸€æ­¥æ“ä½œï¼ˆæ¯”å¦‚å†æ¬¡è°ƒç”¨AIç”Ÿæˆæœ€ç»ˆå›å¤ï¼‰
    }
    else
    {
        Log.Message("AIæ²¡æœ‰å»ºè®®ä»»ä½•å‡½æ•°è°ƒç”¨ï¼Œå¯èƒ½ç›´æ¥å›ç­”äº†é—®é¢˜ã€‚");
        // æˆ–è€…ç›´æ¥æŠŠpromptå‘ç»™SendMessageAsyncè·å–æœ€ç»ˆå›å¤
        var directResponse = await RimAIAPI.SendMessageAsync(prompt);
        Log.Message($"AIç›´æ¥å›å¤: {directResponse}");
    }
}
```

**é¢„æœŸè¾“å‡º**
```
--- å¤„ç†æ–°é—®é¢˜: ç”¨ä¸­æ–‡å›ç­”ï¼šstrawberryä¸­æœ‰å¤šå°‘ä¸ªr? ---
AIå»ºè®®è°ƒç”¨: 'count_letter_in_string'
å‚æ•°: {"a": "strawberry", "b": "r"}

--- å¤„ç†æ–°é—®é¢˜: ç”¨ä¸­æ–‡å›ç­”ï¼š9.11å’Œ9.9ï¼Œå“ªä¸ªå°? ---
AIå»ºè®®è°ƒç”¨: 'compare'
å‚æ•°: {"a": 9.11, "b": 9.9}
```

è¿™ä¸ªåŠŸèƒ½éå¸¸å¼ºå¤§ï¼Œå®ƒå°†AIçš„è‡ªç„¶è¯­è¨€ç†è§£èƒ½åŠ›å’Œä½ çš„ä»£ç æ‰§è¡Œèƒ½åŠ›è¿æ¥äº†èµ·æ¥ï¼Œä¸ºåˆ›é€ æ›´æ™ºèƒ½ã€æ›´å…·äº¤äº’æ€§çš„MODåŠŸèƒ½å¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ã€‚

## âš™ï¸ LLMRequestOptions è¯¦ç»†å‚æ•°

### åŸºç¡€å‚æ•°

```csharp
public class LLMRequestOptions
{
    // æ¸©åº¦æ§åˆ¶ (0.0-2.0)
    public float? Temperature { get; set; }
    
    // æœ€å¤§è¿”å›Tokenæ•°
    public int? MaxTokens { get; set; }
    
    // æ˜¯å¦å¯ç”¨ç¼“å­˜
    public bool EnableCaching { get; set; } = true;
    
    // è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)
    public int? TimeoutSeconds { get; set; }
    
    // é‡è¯•æ¬¡æ•°
    public int? RetryCount { get; set; }
    
    // Top-pé‡‡æ ·å‚æ•°
    public float? TopP { get; set; }
    
    // é¢‘ç‡æƒ©ç½š
    public float? FrequencyPenalty { get; set; }
    
    // å­˜åœ¨æƒ©ç½š
    public float? PresencePenalty { get; set; }
    
    // åœæ­¢è¯åˆ—è¡¨
    public List<string> StopWords { get; set; }
    
    // è‡ªå®šä¹‰HTTPå¤´
    public Dictionary<string, string> CustomHeaders { get; set; }
    
    // ç”¨æˆ·æ ‡è¯†
    public string UserId { get; set; }
}
```

### å‚æ•°è¯¦è§£

**Temperature (float?, 0.0-2.0)**
- æ§åˆ¶å“åº”çš„éšæœºæ€§å’Œåˆ›é€ æ€§
- 0.0: ç¡®å®šæ€§è¾“å‡ºï¼Œé€‚åˆäº‹å®æ€§é—®é¢˜
- 0.7: å¹³è¡¡åˆ›é€ æ€§å’Œå‡†ç¡®æ€§ï¼Œé€‚åˆä¸€èˆ¬å¯¹è¯
- 1.0: æ›´æœ‰åˆ›é€ æ€§ï¼Œé€‚åˆåˆ›æ„å†™ä½œ
- 2.0: é«˜åº¦éšæœºï¼Œé€‚åˆå¤´è„‘é£æš´

```csharp
// äº‹å®æ€§é—®é¢˜ - ä½æ¸©åº¦
var factualOptions = new LLMRequestOptions { Temperature = 0.1f };
var response = await RimAIAPI.SendMessageAsync("RimWorldçš„å‘å¸ƒæ—¶é—´æ˜¯ï¼Ÿ", factualOptions);

// åˆ›æ„å†™ä½œ - é«˜æ¸©åº¦
var creativeOptions = new LLMRequestOptions { Temperature = 1.2f };
var story = await RimAIAPI.SendMessageAsync("å†™ä¸€ä¸ªç§‘å¹»çŸ­æ•…äº‹", creativeOptions);
```

**MaxTokens (int?)**
- é™åˆ¶è¿”å›å†…å®¹çš„é•¿åº¦
- 1 token â‰ˆ 0.75ä¸ªè‹±æ–‡å•è¯ â‰ˆ 0.5ä¸ªä¸­æ–‡å­—ç¬¦
- å»ºè®®å€¼ï¼š50-2000

```csharp
// ç®€çŸ­å›ç­”
var shortOptions = new LLMRequestOptions { MaxTokens = 50 };

// è¯¦ç»†å›ç­”
var detailedOptions = new LLMRequestOptions { MaxTokens = 1000 };
```

**EnableCaching (bool)**
- æ˜¯å¦å¯ç”¨å“åº”ç¼“å­˜
- true: ç›¸åŒè¯·æ±‚ä½¿ç”¨ç¼“å­˜ï¼Œæé«˜æ€§èƒ½
- false: æ¯æ¬¡éƒ½å‘é€æ–°è¯·æ±‚

#### ğŸ” æ·±åº¦è§£æï¼šç¼“å­˜ç›¸ä¼¼æ€§åˆ¤æ–­æœºåˆ¶

**ç¼“å­˜é”®ç”Ÿæˆç®—æ³•**ï¼š
```
ç¼“å­˜é”® = LLM:{æ¶ˆæ¯å“ˆå¸Œ}:temp={Temperature}:maxtok={MaxTokens}:model={Model}:json={JsonMode}:schema={SchemaHash}:topp={TopP}:...
```

**å½±å“ç¼“å­˜å‘½ä¸­çš„å‚æ•°**ï¼š
- **æ¶ˆæ¯å†…å®¹**ï¼šä½¿ç”¨ `GetHashCode()` è®¡ç®—æ–‡æœ¬å“ˆå¸Œ
- **Temperature**ï¼šåˆ›é€ æ€§å‚æ•°ï¼Œå¿…é¡»å®Œå…¨åŒ¹é…
- **MaxTokens**ï¼šæœ€å¤§ä»¤ç‰Œæ•°ï¼Œå¿…é¡»ä¸€è‡´
- **Model**ï¼šAIæ¨¡å‹åç§°
- **ForceJsonMode**ï¼šæ˜¯å¦å¼ºåˆ¶JSONè¾“å‡º
- **JsonSchema**ï¼šJSONæ¶æ„çš„å“ˆå¸Œå€¼
- **TopP**ï¼šTop-pé‡‡æ ·å‚æ•°
- **å…¶ä»–å‚æ•°**ï¼šFrequencyPenaltyã€PresencePenaltyç­‰

**ç›¸ä¼¼æ€§åˆ¤æ–­ç¤ºä¾‹**ï¼š
```csharp
// âœ… è¿™äº›è¯·æ±‚ä¼šè¢«åˆ¤æ–­ä¸ºç›¸åŒï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
var req1 = new LLMRequestOptions { Temperature = 0.7f, MaxTokens = 500 };
var req2 = new LLMRequestOptions { Temperature = 0.7f, MaxTokens = 500 };
// ç¼“å­˜é”®ç›¸åŒï¼šLLM:12345678:temp=0.7:maxtok=500:model=default:json=False

// âŒ è¿™äº›è¯·æ±‚è¢«åˆ¤æ–­ä¸ºä¸åŒï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
var req3 = new LLMRequestOptions { Temperature = 0.8f, MaxTokens = 500 };
// ç¼“å­˜é”®ä¸åŒï¼šLLM:12345678:temp=0.8:maxtok=500:model=default:json=False

var req4 = new LLMRequestOptions { Temperature = 0.7f, MaxTokens = 600 };
// ç¼“å­˜é”®ä¸åŒï¼šLLM:12345678:temp=0.7:maxtok=600:model=default:json=False
```

**ç¼“å­˜ä¼˜åŒ–ç­–ç•¥**ï¼š
```csharp
// âœ… æ ‡å‡†åŒ–é…ç½®æé«˜å‘½ä¸­ç‡
public static class StandardOptions
{
    public static readonly LLMRequestOptions Creative = new LLMRequestOptions 
    { 
        Temperature = 1.0f, MaxTokens = 800, EnableCaching = true 
    };
    
    public static readonly LLMRequestOptions Factual = new LLMRequestOptions 
    { 
        Temperature = 0.2f, MaxTokens = 500, EnableCaching = true 
    };
}

// âœ… é‡å¤ä½¿ç”¨æ ‡å‡†é…ç½®
var response1 = await RimAIAPI.SendMessageAsync("é—®é¢˜1", StandardOptions.Factual);
var response2 = await RimAIAPI.SendMessageAsync("é—®é¢˜2", StandardOptions.Factual);
// å¦‚æœ"é—®é¢˜1"å’Œ"é—®é¢˜2"ç›¸åŒï¼Œä¼šå‘½ä¸­ç¼“å­˜
```

**ç¼“å­˜ç”Ÿå‘½å‘¨æœŸ**ï¼š
- **é»˜è®¤TTL**ï¼š30åˆ†é’Ÿ
- **LRUæ¸…ç†**ï¼šå½“ç¼“å­˜æ¡ç›®è¶…è¿‡æœ€å¤§æ•°é‡æ—¶ï¼Œæ¸…ç†æœ€å°‘ä½¿ç”¨çš„æ¡ç›®
- **è¿‡æœŸæ¸…ç†**ï¼šæ¯2åˆ†é’Ÿè‡ªåŠ¨æ¸…ç†è¿‡æœŸæ¡ç›®
- **å†…å­˜ç›‘æ§**ï¼šä¼°ç®—å†…å­˜ä½¿ç”¨ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼

**TimeoutSeconds (int?)**
- è¯·æ±‚è¶…æ—¶æ—¶é—´
- é»˜è®¤ï¼š30ç§’
- å»ºè®®èŒƒå›´ï¼š5-120ç§’

**RetryCount (int?)**
- å¤±è´¥æ—¶çš„é‡è¯•æ¬¡æ•°
- é»˜è®¤ï¼š3æ¬¡
- å»ºè®®èŒƒå›´ï¼š1-5æ¬¡

## ğŸ­ Optionså·¥å‚æ–¹æ³•

æ¡†æ¶æä¾›é¢„è®¾çš„é…ç½®é€‰é¡¹ï¼Œç®€åŒ–å¸¸ç”¨åœºæ™¯çš„é…ç½®ï¼š

### RimAIAPI.Options é™æ€å·¥å‚

```csharp
// åˆ›æ„æ¨¡å¼ - é«˜æ¸©åº¦ï¼Œé€‚åˆåˆ›æ„å†…å®¹
var creative = RimAIAPI.Options.Creative();
// ç­‰åŒäº: new LLMRequestOptions { Temperature = 1.0f, MaxTokens = 800 }

// äº‹å®æ¨¡å¼ - ä½æ¸©åº¦ï¼Œé€‚åˆäº‹å®é—®ç­”
var factual = RimAIAPI.Options.Factual();  
// ç­‰åŒäº: new LLMRequestOptions { Temperature = 0.2f, MaxTokens = 500 }

// ç»“æ„åŒ–è¾“å‡º - é€‚åˆJSONè¾“å‡º
var structured = RimAIAPI.Options.Structured();
// ç­‰åŒäº: new LLMRequestOptions { Temperature = 0.3f, MaxTokens = 1000 }

// æµå¼ä¼˜åŒ– - é€‚åˆæµå¼å“åº”
var streaming = RimAIAPI.Options.Streaming();
// ç­‰åŒäº: new LLMRequestOptions { EnableCaching = false, MaxTokens = 1500 }
```

### å·¥å‚æ–¹æ³•ä½¿ç”¨ç¤ºä¾‹

```csharp
// åˆ›æ„å†™ä½œ
var story = await RimAIAPI.SendMessageAsync(
    "å†™ä¸€ä¸ªå…³äºå¤ªç©ºæ®–æ°‘çš„æ•…äº‹", 
    RimAIAPI.Options.Creative()
);

// äº‹å®æŸ¥è¯¢
var info = await RimAIAPI.SendMessageAsync(
    "RimWorldä¸­åŒ»ç–—ç³»ç»Ÿæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ", 
    RimAIAPI.Options.Factual()
);

// ç»“æ„åŒ–æ•°æ®
var json = await RimAIAPI.SendMessageAsync(
    "ä»¥JSONæ ¼å¼è¿”å›å½“å‰æ®–æ°‘åœ°çŠ¶æ€", 
    RimAIAPI.Options.Structured()
);
```

## ğŸ“Š ç»Ÿè®¡å’Œç›‘æ§API

### GetStatistics - è·å–æ¡†æ¶ç»Ÿè®¡ä¿¡æ¯

#### æ–¹æ³•ç­¾å
```csharp
public static FrameworkStatistics GetStatistics()
```

#### è¿”å›å€¼ï¼šFrameworkStatistics
```csharp
public class FrameworkStatistics
{
    public int TotalRequests { get; set; }        // æ€»è¯·æ±‚æ•°
    public int SuccessfulRequests { get; set; }  // æˆåŠŸè¯·æ±‚æ•°
    public int FailedRequests { get; set; }      // å¤±è´¥è¯·æ±‚æ•°
    public double AverageResponseTime { get; set; } // å¹³å‡å“åº”æ—¶é—´(ms)
    public int CacheHits { get; set; }           // ç¼“å­˜å‘½ä¸­æ¬¡æ•°
    public int CacheMisses { get; set; }         // ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°
    public double CacheHitRate { get; set; }     // ç¼“å­˜å‘½ä¸­ç‡
    public long TotalTokensUsed { get; set; }    // æ€»æ¶ˆè€—Tokenæ•°
    public DateTime LastRequestTime { get; set; } // æœ€åè¯·æ±‚æ—¶é—´
    public bool IsHealthy { get; set; }          // ç³»ç»Ÿå¥åº·çŠ¶æ€
}
```

#### ä½¿ç”¨ç¤ºä¾‹

```csharp
// è·å–ç»Ÿè®¡ä¿¡æ¯
var stats = RimAIAPI.GetStatistics();

Log.Message($"=== RimAI Framework ç»Ÿè®¡ä¿¡æ¯ ===");
Log.Message($"æ€»è¯·æ±‚æ•°: {stats.TotalRequests}");
Log.Message($"æˆåŠŸç‡: {(stats.SuccessfulRequests * 100.0 / stats.TotalRequests):F1}%");
Log.Message($"å¹³å‡å“åº”æ—¶é—´: {stats.AverageResponseTime:F2}ms");
Log.Message($"ç¼“å­˜å‘½ä¸­ç‡: {stats.CacheHitRate:P2}");
Log.Message($"æ€»æ¶ˆè€—Token: {stats.TotalTokensUsed:N0}");
Log.Message($"ç³»ç»Ÿå¥åº·: {(stats.IsHealthy ? "æ­£å¸¸" : "å¼‚å¸¸")}");

// æ€§èƒ½ç›‘æ§
if (stats.AverageResponseTime > 5000)
{
    Log.Warning("å“åº”æ—¶é—´è¿‡é•¿ï¼Œå»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥");
}

if (stats.CacheHitRate < 0.1)
{
    Log.Warning("ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½ï¼Œå»ºè®®æ£€æŸ¥ç¼“å­˜é…ç½®");
}
```

### ClearCache - æ¸…ç†ç¼“å­˜

#### æ–¹æ³•ç­¾å
```csharp
public static void ClearCache()
```

#### ä½¿ç”¨åœºæ™¯

```csharp
// å®šæœŸæ¸…ç†ç¼“å­˜
if (stats.CacheHits + stats.CacheMisses > 1000)
{
    RimAIAPI.ClearCache();
    Log.Message("ç¼“å­˜å·²æ¸…ç†");
}

// å†…å­˜å‹åŠ›æ—¶æ¸…ç†
var memoryUsage = GC.GetTotalMemory(false);
if (memoryUsage > 100 * 1024 * 1024) // è¶…è¿‡100MB
{
    RimAIAPI.ClearCache();
    GC.Collect();
}
```

## ğŸ”§ é«˜çº§ç”¨æ³•å’Œæœ€ä½³å®è·µ

### ğŸ“¦ æ™ºèƒ½ç¼“å­˜æœºåˆ¶æ·±åº¦è§£æ

#### ç¼“å­˜é”®æ„å»ºç®—æ³•

RimAI Frameworkä½¿ç”¨å¤åˆç¼“å­˜é”®æ¥ç²¾ç¡®è¯†åˆ«ç›¸ä¼¼è¯·æ±‚ï¼š

```csharp
// å†…éƒ¨ç¼“å­˜é”®ç”Ÿæˆé€»è¾‘ï¼ˆç®€åŒ–ç‰ˆï¼‰
private string GenerateCacheKey(string prompt, LLMRequestOptions options)
{
    var keyBuilder = new StringBuilder();
    keyBuilder.Append("LLM:");
    keyBuilder.Append(prompt?.GetHashCode().ToString() ?? "null");
    
    if (options != null)
    {
        keyBuilder.Append($":temp={options.Temperature}");
        keyBuilder.Append($":maxtok={options.MaxTokens}"); 
        keyBuilder.Append($":model={options.Model ?? "default"}");
        keyBuilder.Append($":json={options.ForceJsonMode}");
        
        if (options.JsonSchema != null)
            keyBuilder.Append($":schema={options.JsonSchema.GetHashCode()}");
        if (options.TopP.HasValue)
            keyBuilder.Append($":topp={options.TopP}");
    }
    
    return keyBuilder.ToString();
}
```

#### ç¼“å­˜å‘½ä¸­æ¡ä»¶

**å¿…é¡»å®Œå…¨åŒ¹é…çš„å‚æ•°**ï¼š
1. **æ¶ˆæ¯å†…å®¹**ï¼šå­—ç¬¦ä¸²å®Œå…¨ç›¸åŒ
2. **Temperature**ï¼šç²¾ç¡®åˆ°å°æ•°ç‚¹
3. **MaxTokens**ï¼šæ•°å€¼å®Œå…¨åŒ¹é…
4. **Model**ï¼šæ¨¡å‹åç§°å­—ç¬¦ä¸²åŒ¹é…
5. **ForceJsonMode**ï¼šå¸ƒå°”å€¼åŒ¹é…
6. **JsonSchema**ï¼šæ¶æ„å“ˆå¸Œå€¼åŒ¹é…
7. **TopP**ï¼šå¦‚æœè®¾ç½®ï¼Œå¿…é¡»ç²¾ç¡®åŒ¹é…

#### å®é™…ç¼“å­˜æµ‹è¯•

```csharp
// æµ‹è¯•ç›¸ä¼¼æ€§åˆ¤æ–­
public async Task TestCacheSimilarity()
{
    var stats = RimAIAPI.GetStatistics();
    var initialHits = stats.CacheHits;
    
    // ç¬¬ä¸€æ¬¡è¯·æ±‚ - ç¼“å­˜æœªå‘½ä¸­
    var response1 = await RimAIAPI.SendMessageAsync("Hello World", 
        new LLMRequestOptions { Temperature = 0.7f, MaxTokens = 100 });
    
    // ç¬¬äºŒæ¬¡ç›¸åŒè¯·æ±‚ - åº”è¯¥ç¼“å­˜å‘½ä¸­
    var response2 = await RimAIAPI.SendMessageAsync("Hello World", 
        new LLMRequestOptions { Temperature = 0.7f, MaxTokens = 100 });
    
    // éªŒè¯ç¼“å­˜å‘½ä¸­
    var newStats = RimAIAPI.GetStatistics();
    var cacheHitIncrease = newStats.CacheHits - initialHits;
    
    Log.Message($"ç¼“å­˜å‘½ä¸­æ¬¡æ•°å¢åŠ : {cacheHitIncrease}");
    Log.Message($"ç¬¬äºŒæ¬¡è¯·æ±‚æ¥è‡ªç¼“å­˜: {response2.FromCache}");
}
```

#### ç¼“å­˜ä¼˜åŒ–ç­–ç•¥

**ç­–ç•¥1ï¼šå‚æ•°æ ‡å‡†åŒ–**
```csharp
// âœ… å®šä¹‰æ ‡å‡†å‚æ•°é›†åˆ
public static class CacheOptimizedOptions
{
    // äº‹å®æŸ¥è¯¢ - ä½æ¸©åº¦ï¼Œé«˜ç¼“å­˜å‘½ä¸­
    public static readonly LLMRequestOptions Facts = new LLMRequestOptions
    {
        Temperature = 0.2f,
        MaxTokens = 300,
        EnableCaching = true
    };
    
    // åˆ›æ„å†…å®¹ - é€‚ä¸­æ¸©åº¦ï¼Œå¹³è¡¡åˆ›æ„æ€§å’Œç¼“å­˜
    public static readonly LLMRequestOptions Creative = new LLMRequestOptions
    {
        Temperature = 0.8f,
        MaxTokens = 800,
        EnableCaching = true
    };
    
    // ç»“æ„åŒ–æ•°æ® - å›ºå®šæ ¼å¼ï¼Œé«˜ç¼“å­˜ä»·å€¼
    public static readonly LLMRequestOptions Structured = new LLMRequestOptions
    {
        Temperature = 0.1f,
        MaxTokens = 1000,
        ForceJsonMode = true,
        EnableCaching = true
    };
}
```

**ç­–ç•¥2ï¼šæ¶ˆæ¯æ¨¡æ¿åŒ–**
```csharp
// âœ… ä½¿ç”¨æ¨¡æ¿æé«˜ç›¸ä¼¼æ€§
public class MessageTemplates
{
    public static string AnalyzeColony(string dataType) =>
        $"åˆ†æå½“å‰æ®–æ°‘åœ°çš„{dataType}çŠ¶å†µï¼Œæä¾›è¯¦ç»†æŠ¥å‘Š";
    
    public static string TranslateText(string text, string targetLang) =>
        $"å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆ{targetLang}ï¼š{text}";
}

// ä½¿ç”¨æ¨¡æ¿ - æé«˜ç¼“å­˜å‘½ä¸­
var analysis1 = await RimAIAPI.SendMessageAsync(
    MessageTemplates.AnalyzeColony("é£Ÿç‰©"), 
    CacheOptimizedOptions.Facts
);

var analysis2 = await RimAIAPI.SendMessageAsync(
    MessageTemplates.AnalyzeColony("é˜²å¾¡"), 
    CacheOptimizedOptions.Facts  // ç›¸åŒå‚æ•°ï¼Œå…¶ä»–éƒ¨åˆ†å¯èƒ½å‘½ä¸­ç¼“å­˜
);
```

**ç­–ç•¥3ï¼šç¼“å­˜é¢„çƒ­**
```csharp
// âœ… é¢„çƒ­å¸¸ç”¨è¯·æ±‚ç¼“å­˜
public async Task PrewarmCache()
{
    var commonQueries = new[]
    {
        "å½“å‰æ¸¸æˆçŠ¶æ€å¦‚ä½•ï¼Ÿ",
        "æœ‰ä»€ä¹ˆå»ºè®®ï¼Ÿ",
        "åˆ†æå½“å‰æƒ…å†µ",
        "ä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆï¼Ÿ"
    };
    
    foreach (var query in commonQueries)
    {
        // é¢„çƒ­ç¼“å­˜ï¼Œå¿½ç•¥ç»“æœ
        _ = await RimAIAPI.SendMessageAsync(query, CacheOptimizedOptions.Facts);
    }
    
    Log.Message("ç¼“å­˜é¢„çƒ­å®Œæˆ");
}
```

### 1. å¼‚æ­¥å¤„ç†æœ€ä½³å®è·µ

```csharp
// âœ… æ­£ç¡®ï¼šä½¿ç”¨ConfigureAwait(false)
public async Task ProcessAIRequestAsync(string message)
{
    var response = await RimAIAPI.SendMessageAsync(message)
        .ConfigureAwait(false);
    
    // å¤„ç†å“åº”
    ProcessResponse(response);
}

// âœ… æ­£ç¡®ï¼šå¼‚å¸¸å¤„ç†
public async Task SafeAIRequestAsync(string message)
{
    try
    {
        var response = await RimAIAPI.SendMessageAsync(message);
        if (!string.IsNullOrEmpty(response))
        {
            // æˆåŠŸå¤„ç†
        }
    }
    catch (OperationCanceledException)
    {
        // æ“ä½œè¢«å–æ¶ˆ
    }
    catch (RimAIException ex)
    {
        // RimAIç‰¹å®šå¼‚å¸¸
        Log.Error($"RimAIå¼‚å¸¸: {ex.Message}");
    }
    catch (Exception ex)
    {
        // å…¶ä»–å¼‚å¸¸
        Log.Error($"æœªçŸ¥å¼‚å¸¸: {ex.Message}");
    }
}
```

### 2. æ€§èƒ½ä¼˜åŒ–æŠ€å·§

```csharp
// âœ… ç¼“å­˜ä¼˜åŒ–ï¼šç›¸ä¼¼è¯·æ±‚ä½¿ç”¨ç¼“å­˜
var options = new LLMRequestOptions 
{ 
    EnableCaching = true,
    Temperature = 0.3f // ä½æ¸©åº¦æé«˜ç¼“å­˜å‘½ä¸­ç‡
};

// âœ… æ‰¹é‡å¤„ç†ï¼šå‡å°‘ç½‘ç»œå¼€é”€
var messages = new List<string> { /* å¤šä¸ªæ¶ˆæ¯ */ };
var responses = await RimAIAPI.SendBatchRequestAsync(messages, options);

// âœ… è¶…æ—¶æ§åˆ¶ï¼šé¿å…é•¿æ—¶é—´ç­‰å¾…
var timeoutOptions = new LLMRequestOptions 
{ 
    TimeoutSeconds = 15,
    RetryCount = 2
};
```

### 3. å†…å­˜ç®¡ç†

```csharp
// âœ… å®šæœŸæ¸…ç†ç¼“å­˜
public class AIManager
{
    private static DateTime lastCacheClean = DateTime.MinValue;
    
    public async Task<string> ProcessRequestAsync(string message)
    {
        // æ¯å°æ—¶æ¸…ç†ä¸€æ¬¡ç¼“å­˜
        if (DateTime.Now - lastCacheClean > TimeSpan.FromHours(1))
        {
            RimAIAPI.ClearCache();
            lastCacheClean = DateTime.Now;
        }
        
        return await RimAIAPI.SendMessageAsync(message);
    }
}
```

### 4. é”™è¯¯å¤„ç†ç­–ç•¥

```csharp
public async Task<string> ResilientRequestAsync(string message, int maxRetries = 3)
{
    for (int attempt = 0; attempt < maxRetries; attempt++)
    {
        try
        {
            var response = await RimAIAPI.SendMessageAsync(message);
            if (!string.IsNullOrEmpty(response))
                return response;
                
            // å¤±è´¥æ—¶ç­‰å¾…åé‡è¯•
            await Task.Delay(TimeSpan.FromSeconds(Math.Pow(2, attempt)));
        }
        catch (Exception ex)
        {
            if (attempt == maxRetries - 1)
                throw; // æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                
            Log.Warning($"è¯·æ±‚å¤±è´¥ï¼Œ{attempt + 1}/{maxRetries}ï¼Œç­‰å¾…é‡è¯•: {ex.Message}");
            await Task.Delay(TimeSpan.FromSeconds(Math.Pow(2, attempt)));
        }
    }
    
    throw new InvalidOperationException($"è¯·æ±‚åœ¨{maxRetries}æ¬¡å°è¯•åä»ç„¶å¤±è´¥");
}
```

## ğŸš¨ å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ

### 1. ç½‘ç»œè¿æ¥é”™è¯¯
```csharp
// é”™è¯¯ï¼šConnectionException
// è§£å†³ï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œå¢åŠ é‡è¯•æ¬¡æ•°
var options = new LLMRequestOptions 
{ 
    TimeoutSeconds = 60,
    RetryCount = 5
};
```

### 2. Tokené™åˆ¶é”™è¯¯
```csharp
// é”™è¯¯ï¼šTokenLimitException  
// è§£å†³ï¼šå‡å°‘MaxTokensæˆ–åˆ†å‰²é•¿æ¶ˆæ¯
var options = new LLMRequestOptions { MaxTokens = 500 };

// æˆ–è€…åˆ†å‰²é•¿æ¶ˆæ¯
if (message.Length > 2000)
{
    var chunks = SplitMessage(message, 2000);
    var responses = await RimAIAPI.SendBatchRequestAsync(chunks);
}
```

### 3. é…ç½®é”™è¯¯
```csharp
// é”™è¯¯ï¼šConfigurationException
// è§£å†³ï¼šæ£€æŸ¥é…ç½®æ–‡ä»¶å’ŒAPIå¯†é’¥
try
{
    var response = await RimAIAPI.SendMessageAsync(message);
}
catch (ConfigurationException ex)
{
    Log.Error($"é…ç½®é”™è¯¯: {ex.Message}");
    Log.Error("è¯·æ£€æŸ¥ RimAIConfig.json æ–‡ä»¶å’ŒAPIå¯†é’¥è®¾ç½®");
}
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [å¿«é€Ÿä¸Šæ‰‹æŒ‡å—](CN_v3.0_APIå¿«é€Ÿä¸Šæ‰‹.md) - å¿«é€Ÿå…¥é—¨å’Œå¸¸ç”¨åœºæ™¯
- [åŠŸèƒ½ç‰¹æ€§](CN_v3.0_åŠŸèƒ½ç‰¹æ€§.md) - è¯¦ç»†åŠŸèƒ½ä»‹ç»
- [è¿ç§»æŒ‡å—](CN_v3.0_è¿ç§»æŒ‡å—.md) - ä»v2.xå‡çº§æŒ‡å¯¼
- [æ¶æ„è®¾è®¡](CN_v3.0_æ¶æ„æ”¹é€ å®ŒæˆæŠ¥å‘Š.md) - æŠ€æœ¯æ¶æ„æ–‡æ¡£

**RimAI Framework v3.0 - è®©AIé›†æˆå˜å¾—ç®€å•è€Œå¼ºå¤§ï¼** ğŸš€
