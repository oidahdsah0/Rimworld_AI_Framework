[h1]ğŸ¤– RimAI Framework - AI-Powered RimWorld Experience[/h1]

[h1]ğŸ”§ Core Framework Module[/h1]
The RimAI Framework is the foundational core of the entire RimAI ecosystem. It is a dependency that handles all communication with Large Language Models (LLMs) and provides a comprehensive API for other content mods.

[h1]âš¡ V4.2.1 Key Features[/h1]
[list]
[*]ğŸ”Œ [b]Data-Driven:[/b] Connect to any AI provider (OpenAI, Ollama, Groq, etc.) via simple JSON templates.
[*]ğŸ”„ [b]End-to-End Streaming:[/b] A fully-featured streaming API for real-time, word-by-word responses.
[*]âœ¨ [b]First-Class Embedding Support:[/b] High-performance API for complex semantic understanding and memory functions.
[*]ğŸ“Š [b]Advanced Batching:[/b] Optimized concurrent requests for chat and embeddings to maximize throughput.
[*]ğŸ  [b]Full support for local OpenAI-compatible APIs[/b] (Ollama, vLLM, etc.)
[/list]

[h1]ğŸ”‘ IMPORTANT: Setup Required Before Use[/h1]

[b]âš ï¸ You MUST configure the mod settings before use! âš ï¸[/b]

[b]Step-by-Step Setup Guide:[/b]
[olist]
[*] [b]Enable the mod[/b] and restart RimWorld.
[*] Go to [b]Settings â†’ Mod Settings â†’ RimAI Framework[/b].
[*] [b]Fill in the required fields:[/b]
    [list]
    [*] [b]API Key:[/b] Your key for services like OpenAI. (Leave empty for local providers like Ollama).
    [*] [b]Endpoint URL:[/b] The base URL for the API. [b]This is usually pre-filled for you.[/b] Only change it if you have a specific need or the official URL changes. (e.g., `https://api.openai.com/v1` for OpenAI, `http://localhost:11434/v1` for local Ollama).
    [*] [b]Model Name:[/b] The exact model name (e.g., `gpt-4o-mini`, `llama3`).
    [/list]
[*] Use the [b]Test Connection[/b] button to verify your settings.
[*] [b]Save[/b] your configuration. You're ready to go!
[/olist]

[b]ğŸ’¡ Quick Start Recommendations:[/b]
[list]
[*] [b]Free option:[/b] Install Ollama locally with a model like `llama3`.
[*] [b]Budget option:[/b] Use OpenAI's `gpt-4o-mini` model (very affordable, ~$0.15 per 1M tokens).
[/list]

[h1]ğŸ’° Important Cost Notice[/h1]
[b]âš ï¸ Token costs are paid directly to your AI service provider, NOT to the mod author! âš ï¸[/b] The mod author receives no payment from your API usage. Local models like Ollama are free to run after initial setup.

[h1]ğŸ“‹ Important Notice[/h1]
This framework itself does not add any gameplay content but is a [b]required dependency[/b] for all other RimAI modules.

[h1]ğŸ¯ Supported Versions[/h1]
âœ… RimWorld 1.5
âœ… RimWorld 1.6

[h1]ğŸ›¡ï¸ Open Source & Security[/h1]
This project is completely open-source. You can review the source code, contribute, and report issues on our GitHub repository: [url=https://github.com/oidahdsah0/Rimworld_AI_Framework]github.com/oidahdsah0/Rimworld_AI_Framework[/url]

[b]ğŸ”¥ If you enjoy this project, please give it a thumbs-up ğŸ‘ and follow â• for updates on more RimAI modules![/b]
