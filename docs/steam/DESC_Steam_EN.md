[h1]🤖 RimAI Framework - AI-Powered RimWorld Experience[/h1]

[h1]🔧 Core Framework Module[/h1]
The RimAI Framework is the foundational core of the entire RimAI ecosystem. It is a dependency that handles all communication with Large Language Models (LLMs) and provides a comprehensive API for other content mods.

[h1]⚡ V4.2.1 Key Features[/h1]
[list]
[*]🔌 [b]Data-Driven:[/b] Connect to any AI provider (OpenAI, Ollama, Groq, etc.) via simple JSON templates.
[*]🔄 [b]End-to-End Streaming:[/b] A fully-featured streaming API for real-time, word-by-word responses.
[*]✨ [b]First-Class Embedding Support:[/b] High-performance API for complex semantic understanding and memory functions.
[*]📊 [b]Advanced Batching:[/b] Optimized concurrent requests for chat and embeddings to maximize throughput.
[*]🏠 [b]Full support for local OpenAI-compatible APIs[/b] (Ollama, vLLM, etc.)
[/list]

[h1]🔑 IMPORTANT: Setup Required Before Use[/h1]

[b]⚠️ You MUST configure the mod settings before use! ⚠️[/b]

[b]Step-by-Step Setup Guide:[/b]
[olist]
[*] [b]Enable the mod[/b] and restart RimWorld.
[*] Go to [b]Settings → Mod Settings → RimAI Framework[/b].
[*] [b]Fill in the required fields:[/b]
    [list]
    [*] [b]API Key:[/b] Your key for services like OpenAI. (Leave empty for local providers like Ollama).
    [*] [b]Endpoint URL:[/b] The base URL for the API. [b]This is usually pre-filled for you.[/b] Only change it if you have a specific need or the official URL changes. (e.g., `https://api.openai.com/v1` for OpenAI, `http://localhost:11434/v1` for local Ollama).
    [*] [b]Model Name:[/b] The exact model name (e.g., `gpt-4o-mini`, `llama3`).
    [/list]
[*] Use the [b]Test Connection[/b] button to verify your settings.
[*] [b]Save[/b] your configuration. You're ready to go!
[/olist]

[b]💡 Quick Start Recommendations:[/b]
[list]
[*] [b]Free option:[/b] Install Ollama locally with a model like `llama3`.
[*] [b]Budget option:[/b] Use OpenAI's `gpt-4o-mini` model (very affordable, ~$0.15 per 1M tokens).
[/list]

[h1]💰 Important Cost Notice[/h1]
[b]⚠️ Token costs are paid directly to your AI service provider, NOT to the mod author! ⚠️[/b] The mod author receives no payment from your API usage. Local models like Ollama are free to run after initial setup.

[h1]📋 Important Notice[/h1]
This framework itself does not add any gameplay content but is a [b]required dependency[/b] for all other RimAI modules.

[h1]🎯 Supported Versions[/h1]
✅ RimWorld 1.5
✅ RimWorld 1.6

[h1]🛡️ Open Source & Security[/h1]
This project is completely open-source. You can review the source code, contribute, and report issues on our GitHub repository: [url=https://github.com/oidahdsah0/Rimworld_AI_Framework]github.com/oidahdsah0/Rimworld_AI_Framework[/url]

[b]🔥 If you enjoy this project, please give it a thumbs-up 👍 and follow ➕ for updates on more RimAI modules![/b]
